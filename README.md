
تشخیص نوع سنگ های تزئینی بر اساس الگوی بافت آن ها

چکيده

یکی از کاربردی ترین مسائل در حوزه ماشین بینایی، تشخیص نوع و دسته بندی
تصاویر است. دو مرحله اصلی تشخیص نوع تصاویر شامل استخراج ویژگی های تصویر
و تشکیل مدل دسته بندی می باشد. ویژگی های بافتی تصویر از جمله مهمترین
ویژگی های قابل استفاده در تحلیل تصاویر، به شمار می آیند. روش های مختلفی
برای استخراج ویژگی های بافتی پیشنهاد شده است که وجه اشتراک همه آنها تلاش
برای یافتن ارتباط بین پیکسل های تصویر در همسایگی های محلی است.

پس از استخراج ویژگی های بافتی، باید به مدلی برای یادگیری این ویژگی ها
توسط ماشین دست پیدا کنیم. هدف از تشکیل این مدل، رسیدن به تابعی است که
مجموعه ویژگی های بافتی داده شده را به دسته مناسب نگاشت می دهد. روش های
مختلفی برای دسته بندی وجود دارد که بسته به حیطه کاربرد، هر کدام از آن ها
می تواند مفید باشد.

در این پروژه، نمونه های ورودی، تصاویر سطح سنگ های تزئینی از چهار معدن
سنگ مختلف هستند. هدف از انجام پروژه، تعیین معدن سنگ برای نمونه های جدید
است. برای استخراج ویژگی های بافتی از یکی از روش های آماری تحت عنوان
ماتریس تکرار استفاده شده است که در یک همسایگی کوچک، وابستگی بین پیکسل
های تصویر را مدل می کند. برای دسته بندی از دو روش درخت تصمیم و ماشین
بردار پشتیبان استفاده شده است.

**واژه‌هاي كليدي:** دسته بندی بافت، تحلیل بافت، ویژگی بافتی، درخت تصمیم،
ماشین بردار پشتیبان

فهرست مطالب

[فصل 1: مقدمه 6](#_Toc335208978)

[1-1- مقدمه 7](#_Toc209236399)

[1-2- مفهوم بافت 8](#_Toc209236401)

[1-3- بافت از دیدگاه فیزیک روان 10](#_Toc335208981)

[فصل 2: کاربردهای تحلیل بافت 14](#_Toc335208982)

[2-1- مقدمه 15](#_Toc209236405)

[2-2- وارسی هوشمند 16](#_Toc335208984)

[2-3- تحلیل تصاویر پزشکی 17](#_Toc335208985)

[2-4- پردازش اسناد 18](#_Toc335208986)

[2-5- سنجش از دور 19](#_Toc335208987)

[فصل 3: روش های تحلیل بافت و استخراج ویژگی های بافتی 22](#_Toc335208988)

[3-1- مقدمه 22](#_Toc209236409)

[3-2- روش های آماری 23](#_Toc335208990)

[3-2-2- ماتریس تکرار 24](#_Toc335208991)

[3-2-3- ویژگی های مربوط به هبستگی 29](#_Toc334914802)

[3-3- روش های هندسی 31](#_Toc335208993)

[3-3-1- ویژگی های موزائیک بندیvoronoi 31](#_Toc334914804)

[3-3-2- روش های ساختاری 35](#_Toc334914805)

[3-4- روش های مبتنی بر مدل 36](#_Toc335208996)

[3-4-1- مدل فیلدهای تصادفی 36](#_Toc334914807)

[3-4-2- فراکتال ها 39](#_Toc334914808)

[3-5- روش های پردازش سیگنال 43](#_Toc335208999)

[3-5-1- فیلترهای دامنه فضایی 43](#_Toc334914810)

[3-5-2- فیلتر دامنه فوریه 45](#_Toc334914811)

[فصل 4: یادگیری و دسته بندی بافت تصاویر 47](#_Toc335209002)

[4-1- مقدمات دسته بندی 48](#_Toc335209003)

[4-2- دسته بندی به روش درخت تصمیم 52](#_Toc335209004)

[4-3- دسته بندی به روش ماشین بردار پشتیبان 55](#_Toc335209005)

[فصل 5: نتایج 66](#_Toc335209006)

فهرست اشکال

[شکل (1-1) جداسازی نواحی بافتی یک تصویر 10](#_Toc335208178)

[شکل (1-2) جفت بافت های با آماره های دسته دوم یکسان. 11](#_Toc335208180)

[شکل (2-1) نمونه هایی از حوزه های کاربردی تحلیل بافت 15](#_Toc335208182)

[شکل (3-1) وابستگی ویژگی های آماری بافت 24](#_Toc335208184)

[شکل (3-2) ماسک های مکعبی مورد استفاده در مدل کردن بافت
29](#_Toc335208186)

[شکل (3-3) ویژگی های به دست آمده از طیف توان. 30](#_Toc335208188)

[شکل (3-4) تقسیم دامنه فرکانس به حلقه ها و محورها 30](#_Toc335208190)

[شکل (3-5) موزائیک بندی voronoi . 32](#_Toc335208192)

[شکل (3-6) جداسازی بافت های تصویر با استفاده از موزائیک بندی voronoi
33](#_Toc335208194)

[شکل (3-7) دسته های ممکن برای همسایگی مرتبه دوم 37](#_Toc335208196)

[شکل (3-8) نتایج جداسازی با استفاده از ویژگی های بافتی مبتنی بر گشتاور
45](#_Toc335208198)

[شکل (4-1) مدل پیشگویانه به صورت یک جعبه سیاه 49](#_Toc335208200)

[شکل (4-2) رویکرد کلی در حل مسائل دسته بندی 50](#_Toc335208202)

[شکل (4-3) کاربرد درخت تصمیم برای تعیین دسته یک جاندار شناخته نشده.
53](#_Toc335208204)

[شکل (4-4) ابر صفحه های بی شمار برای جدا کردن نمونه ها به دو کلاس مختلف
55](#_Toc335208206)

[شکل (4-5) مقایسه حاشیه های دوابرصفحه جداکننده 56](#_Toc335208208)

[شکل (4-6) معادلات مربوط به ابرصفحه جداکننده و حاشیه آن.
58](#_Toc335208210)

[شکل (4-7) مقایسه دو ابرصفحه برای جدا کردن نمونه ها 63](#_Toc335208212)

[شکل (4-8) یک مرز تصمیم با حاشیه بزرگ اما خطاهای زیاد.
64](#_Toc335208214)

[شکل (5-1) نمودار پراکندگی ویژگی های استخراج شده از بافت تصاویر سنگ.
67](#_Toc335208216)

[شکل (5-2) حالت خطا در آزمون روش درخت تصمیم. 68](#_Toc335208216)

[شکل (5-3) چهار حالت خطای اول آزمون روش ماشین بردار پشتیبان.
69](#_Toc335208216)

[شکل (5-4) حالت خطای پنجم آزمون روش بردار پشتیبان. 70](#_Toc335208216)

1.  \
    []{#_Toc335208978 .anchor}مقدمه

    1.  []{#_Toc209236399 .anchor}مقدمه

یکی از مهمترین کاربردهای رایانه در زندگی امروز بشر، انجام کارهای روزمره
و تکراری است که نیاز به صرف زمان بسیار دارد. در بعضی از این کارها رایانه
باید بتواند، همانند یک انسان تازه کار، آموزش ببیند و بر اساس آموخته های
خویش، در شرایط جدید قادر به اتخاذ تصمیمات مناسب باشد. انسان به مرور زمان
در کار خویش تجربه کسب می کند و با توجه به تجربیات جدید، کار خود را دقیق
تر انجام می دهد و خطاهایش را کاهش می دهد. رایانه نیز با بهره گیری از
حافظه خود، می تواند تجربیات را ثبت کند و بر اساس این تجربیات به مرور
خطای خود را کاهش دهد. از دیگر سو خطاهای ناشی از خستگی و کار زیاد، خطای
دید و یا نقص اعضاء در نتایج کار انسان مؤثر است اما این عوامل بر نتایج
کار رایانه اثری ندارد و امید به کسب نتایج بهتر توسط رایانه، عجیب نیست.

یکی از نیازهای صنایع سنگ کشورمان، دستگاه تشخیص و جداسازی سنگ های تزئینی
است. این دستگاه باید قادر باشد با دریافت نوع های مختلف سنگ، الگوی بافتی
آن ها را یاد بگیرد و برای نمونه های شناخته نشده، دسته مناسب را تعیین
کند.

وقتی صحبت از تشخیص به میان می آید با مبحث دسته بندی در حوزه یادگیری
ماشین مواجه خواهیم بود. دسته بندی با داده های ارضاء شده سروکار دارد بدین
معنا که داده ها دارای برچسب هستند و در دسته های متمایز قرار می گیرند.
این که یک نمونه جدید به کدام دسته تعلق دارد بر اساس ویژگی هایش تعیین می
شود. بنابراین باید با توجه به ویژگی های داده های آموزش به مدلی دست پیدا
کنیم که ویژگی های یک نمونه را به عنوان ورودی دریافت کند و برچسب آن را به
عنوان خروجی تحویل دهد. پس در گام نخست باید ویژگی های نمونه ها را به دست
آورده باشیم.

در این پروژه داده های خام، تصاویر سطح سنگ هستند. باید با استفاده از
مکانیزمی، ویژگی های بافت تصاویر را برای استفاده در دسته بندی استخراج
کنیم. یک تصویر چیزی نیست جز یک ماتریس که هر درایه آن توصیفگر یک سلول
رزولوشن تصویر است. مکانیزم مورد استفاده باید قادر باشد وابستگی های بین
این سلول ها را به خوبی به تصویر بکشد و انتزاعی مناسب از این ویژگی ها به
دست دهد. روش های مختلفی در استخراج ویژگی های بافتی تصویر مورد استفاده
قرار می گیرند که بسته به حیطه کاربرد، هر کدام از آن روش ها می توانند
مناسب باشند. در این پروژه از یکی از روش های آماری تحت عنوان ماتریس تکرار
برای استخراج ویژگی های بافتی استفاده کرده ایم و در دسته بندی، روش های
درخت تصمیم و ماشین بردار پشتیبان را به کار برده ایم.

2.  []{#_Toc209236401 .anchor}مفهوم بافت

    بافت تصویر، واژه ای است که برای توصیف سطح یک شیء به کار می رود و جزء
    ویژگی های اصلی مورد استفاده در پردازش تصویر و تشخیص الگو به شمار می
    آید؛ به همین علت مطالعه بر روی تحلیل بافت ها در سال های اخیر بسیار
    مورد توجه قرار گرفته است. تحلیل بافت نیازمند تعیین ویژگی های توصیفی
    بافت هاست که آنها را برای تفکیک[^1]، دسته بندی[^2] و تشخیص[^3]
    متمایز می کند.

در بسیاری از الگوریتم های ماشین بینایی و پردازش تصویر، ساده ترین فرض ها
در مورد یکنواختی تیرگی در نواحی محلی تصویر صورت می گیرد؛ اما تصویر اشیای
واقعی معمولاً شامل نواحی با شدت کاملاً همسان نمی باشد. به عنوان مثال
تصویر یک سطح چوبی یکنواخت نیست بلکه شامل مقادیر متغیری است که الگوهای
تکراری مشخصی را شکل می دهند. به این الگو ها بافت بصری[^4] گفته می شود.
الگوها می توانند حاصل ویژگی های فیزیکی سطح مانند سختی و یا لایه های ارث
برده که معمولاً دارای جنبه لمسی هستند و یا حاصل بازتاب تفاوت هایی چون
رنگ باشند.

ما هنگامی که یک بافت را می بینیم می توانیم آن را تشخیص دهیم اما تعریف
کردن بافت برای ما کار آسانی نیست. این دشواری توسط تعدادی از تعاریفی که
توسط پژوهشگران حوزه ماشین بینایی صورت گرفته، شرح داده شده است.
کوژینز[^5] لیستی از تعاریف بافت را در ماشین بینایی جمع آوری کرده است که
در ادامه چند نمونه از آن تعاریف آورده شده است:

-   ما می توانیم بافت را توزیع یک ناحیه ماکروسکوپی درنظر بگیریم. ساختار
    بافت به سادگی توسط الگوهای تکراری که در آن المان ها و یا عناصر
    بنیادین بر اساس یک قانون جایگذاری، شکل گرفته اند، قابل توصیف است.

-   یک ناحیه در یک تصویر دارای یک بافت ثابت است اگر مجموعه ای از آماره
    های محلی و یا سایر ویژگی های محلی یک تصویر در آن ثابت باشد و یا به
    آرامی تغییر کند و یا متناوب باشد.

-   بافت تصویری که ما با آن سروکار داریم غیرقابل ترسیم و سلولی است. یک
    بافت تصویری توسط تعداد و نوع عناصر بنیادین و سازماندهی فضایی آنها و
    یا لایه های عناصر بنیادین تعریف می شود. یک ویژگی اساسی بافت این است
    که بدون قابی از ساختارهای بنیادینِ وابسته به شدت نقاط قابل تحلیل
    نیستند. برای هر سطح نرم، بازه ای از درجه تیرگی وجود دارد که از آن
    بازه به بعد، هیچ بافتی را نمی توان برای سطح در نظر گرفت. با بالا
    رفتن رزولوشن تصویر یک بافت خوب به خود می گیرد و دارای یک بافت نسبتاً
    پیچیده می شود.

-   بافت در تعریف ما تخصیص یک فیلد است که هیچ جزء کوچکتری ندارد و عناصر
    بنیادین آن قابل ردیابی و تطبیق هستند اما روابط بین اجزاء قابل مشاهده
    نیستند.

-   بافت مفهومی متناقض به نظر می آید. زیرا از یک سو در پردازش اطلاعات
    گرافیکی به خصوص در حوزه دسته بندی کاربردی تصاویر بسیار مورد استفاده
    قرار می گیرد و از دیگر سو هیچ کس نتوانسته است یک تعریف همه پسند از
    بافت ارائه کند.

-   مفهوم بافت به سه عامل بستگی دارد: 1- تعدادی از بخش های محلی درون یک
    ناحیه بافت تکرار می شوند که به نسبت سایر مقیاس ها، بزرگتر هستند. 2-
    قطعات بنیادین موجود در تصویر دارای یک چینش غیرتصادفی هستند. 3- قطعات
    بافت موجودیت های کاملاً یکنواختی هستند که در ناحیه بافت تقریباً
    دارای مقیاس مشابهی هستند.

> این مجموعه تعاریف از مفهوم بافت نشان می دهند که تعریف بافت توسط افراد
> مختلف بسته به حوزه کاربردشان صورت پذیرفته است و تعریف جامع و همه پسندی
> از مفهوم بافت ارائه نشده است.
>
> بافت تصویر تابعی از تغییرات فضایی شدت پیکسل ها می باشد که در بسیاری از
> کاربردها مورد استفاده قرار می گیرد و زمینه مطالعه بسیاری از پژوهشگران
> است. یکی از کاربردهای ساده بافت تصاویر، تشخیص نواحی تصویر با استفاده
> از ویژگی های بافت است. به عنوان مثال در تصویر زیر (قسمت a) می توانیم
> پنج بافت متفاوت را تشخیص دهیم. بافت مهمترین ابزار بصری در تشخیص این
> نواحی یکنواخت است. به این کار دسته بندی بافت می گویند.

![](media/image3.png){width="5.518055555555556in"
height="2.091666666666667in"}

1.  []{#_Toc335208178 .anchor}جداسازی نواحی بافتی یک تصویر

> هدف از دسته بندی رسیدن به یک نقشه است که تصاویر مختلفی را به عنوان
> ورودی دریافت می کند و دسته آنها را تعیین می نماید.
>
> اگر قادر به تعیین دسته بافت های موجود در یک تصویر نباشیم اما بتوانیم
> مرز بافت ها را مشخص کنیم با دسته دیگری از مسائل در تحلیل بافتها مواجه
> می شویم که به آن قطعه بندی بافت[^6] می گویند. هدف از قطعه بندی تصویر
> رسیدن به نقشه ای مشابه با قسمت c از 1-1 است که از طریق آن مرز بافت ها
> به خوبی مشخص می شود. سنتز بافت[^7] معمولاً در برنامه های فشرده سازی
> تصویر کاربرد دارد. همچنین در گرافیک کامپیوتری زمانی که بخواهیم سطح
> اشیاء را تا جای ممکن به سطح واقعی خود نزدیک کنیم سنتز بافت اهمیت زیادی
> پیدا می کند. مسأله استخراج شکل از بافت نمونه ای از مسائل کلی بینایی
> است که در آن هدف به دست آوردن اطلاعات شکل سه بعدی از ویژگی هایی چون
> سایه، استریو و بافت است. ویژگی های بافت (المان های بافت) در پردازش
> تصویر مورد استفاده قرار می گیرد و جهت یابی فضایی اجسام را نتیجه می
> دهد.

3.  []{#_Toc335208981 .anchor}بافت از دیدگاه فیزیک روان

> یافتن یک ببر از میان برگهای درختان برای کسی که می خواهد در یک جنگل جان
> سالم به در ببرد مساله ای بسیار حیاتی است. موفقیت ببر در استتار خود
> معادل شکست سیستم بینایی در یافتن آن است. زمانی ما در این عملیات شکست
> می خوریم که نتوانیم شکل را از زمینه تمییز دهیم. جداسازی شکل از زمینه
> موضوعی است که دانشمندان فیزیک روان علاقه زیادی به آن دارند. جداسازی
> شکل از زمینه می تواند با استفاده از ابزارهای متعددی چون روشنی، شکل،
> رنگ، بافت و \... امکان پذیر است. در مثال ببر در جنگل، بافت یک نقش
> اساسی را ایفا می کند. استتار ببر، موفقیت آمیز است به این دلیل که سیستم
> بینایی مشاهده کننده قادر به تمییز دو نوع بافت یعنی بافت برگ درختان و
> بافت بدن ببر نمی باشد. فرایند بصری که به یک شخص امکان جدا کردن یک شکل
> از زمینه اش را با استفاده از بافت می دهد، چیست؟ این سؤال انگیزه اصلی
> برای دانشمندان فیزیک روان در مطالعه مفهوم بافت است.
>
> دلیل دیگر مطالعه مفهوم فیزیکی بافت، این است که عملکرد الگوریتم های
> مختلفی که بر روی بافت کار می کنند با عملکرد سیستم بینایی انسان در
> عملیاتی مشابه سنجیده می شود. برای مثال به دو نوع بافت در قسمت a از شکل
> 1-2 نگاه کنید که اولین بار توسط ژولز[^8] مطرح شد. این تصویر شامل دو
> ناحیه است که هر کدام از آنها از اجزای بافتی متفاوتی تشکیل شده اند.
> موشکافی دقیق بافت تصویر این حقیقت را به بیننده انسان نشان می دهد. درک
> بلادرنگ تصویر بعد از درک دو ناحیه بافتی متفاوت تصویر نتیجه نمی شود
> بلکه یک ناحیه بافتی یکنواخت توسط بیننده انسان دریافت می شود. ژولز چنین
> جفت بافت هایی را به سختی قابل تمییز می داند.

![](media/image4.png){width="5.605504155730534in"
height="2.7051345144356955in"}

2.  []{#_Toc335208180 .anchor}جفت بافت های با آماره های دسته دوم یکسان.
    هر دو تصویر شامل دو جفت بافت می شوند که جفت بافت های تصویر a توسط
    انسان قابل تمییز نیست اما جفت بافت های تصویر b توسط انسان قابل تفکیک
    و تمییز است.

> چنین بافت های ترکیبی به ما در شکل گرفتن فرضیه ای درباره اینکه چه ویژگی
> هایی از تصویر در درک تصاویر توسط انسان، مهم هستند، کمک می کند. همچنین
> این مثال، سوال دیگری را در ذهن شکل می دهد: چگونه عملکرد الگوریتم های
> کامپیوتری تحلیل بافت را مورد ارزیابی قرار دهیم؟ به عنوان مثال فرض کنید
> الگوریتمی داریم که می تواند دو نوع بافت را در تصویر ذکر شده از هم
> تمییز دهد. آیا این الگوریتم، الگوریتم صحیحی است؟ البته پاسخ این سوال
> بستگی به هدف الگوریتم دارد. اگر یک الگوریتم خاص منظوره باشد که باید
> قادر به تشخیص چنین ناحیه هایی باشد، پس الگوریتم کار خود را به خوبی
> انجام داده است اما اگر هدف الگوریتم شبیه سازی رفتار انسان باشد، این
> الگوریتم غلط کار می کند.
>
> ژولز مفهوم بافت را در زمینه تفکیک بافت ها مورد مطالعه قرار داده است.
> سوالی که او مطرح می کند این است که «چه زمانی جفت بافت های موجود در
> تصویری که میزان روشنی، کنتراست و رنگ آن داده شده است، قابل تفکیک اند؟»
> او بر روی آماره های فضایی سطوح تیرگی تصویر متمرکز شد. این آماره ها (با
> ثابت در نظر گرفتن سایر ویژگی های وابسته به روشنی)، برای یک بافت آماره
> های ذاتی به حساب می آیند.
>
> حال به معرفی آماره های دسته اول و آماره های دسته دوم در تحلیل بافت ها
> می پردازیم.
>
> **آماره های دسته اول:** این آماره ها به اندازه گیری مشابهت مقدار تیرگی
> مشاهده شده در یک ناحیه تصادفی از تصویر می پردازند. آماره های دسته اول
> می توانند از هیستوگرامی از درجه تیرگی نقاط در تصویر محاسبه شوند. این
> آماره ها به مقادیر تیرگی پیکسل ها بستگی دارند و به تعامل و همبستگی
> مقادیر پیسکل های مجاور بستگی ندارند. میانگین درجه تیرگی در یک تصویر،
> مثالی از آماره های دسته اول می باشد.
>
> **آماره های دسته دوم:** این آماره ها میزان مشابهت یک جفت پیکسل را که
> در نقاط انتهایی یک محور با طول تصادفی که بر مکانی خاص و با جهت یابی
> خاص بر روی تصویر قرار می گیرند، اندازه گیری می کنند.
>
> ژولز می گوید دو نوع بافت قابل تمییزند اگر آماره های دسته دوم آنها
> یکسان باشد. این موضوع در تصویر قبل کاملاً مشهود است. این تصویر دارای
> دو ناحیه بافتی متفاوت است که آماره های دسته دوم آنها یکسان هستند.
>
> ژولز نظریه بافت واره ها[^9] را مطرح کرد تا غیر قابل تمییز بودن جفت
> بافت ها را شرح دهد. بافت واره ها رویدادهای بصری(نظیر خاتمه[^10] و بسته
> شدن[^11]) هستند که در فرایند تفکیک بافت حضور دارند. خاتمه ها نقاط
> انتهایی خطوط یا گوشه ها هستند. ژولز با استفاده از نظریه بافت واره ها
> مثال های شکل 1-2 را بدین گونه توضیح داد: یادآور می شویم که هردو تصویر
> بافتی در این شکل دارای دو ناحیه با آماره های دسته دوم یکسان هستند. در
> قسمت a تعداد خاتمه ها در هر دو ناحیه فوقانی و زیرین یکسان است. به همین
> دلیل سیستم بصری در تفکیک دو بافت عاجز است. اما در شکل b تعداد خاتمه ها
> در نیمه فوقانی سه تاست و تعداد آنها در نیمه تحتانی چهارتاست. این تفاوت
> در بافت واره ها دو ناحیه بافتی را قابل تفکیک می کند.
>
> مطالعات در فیزیک روان به این نتیجه رسیده است که تحلیل چند کاناله
> فرکانس و جهت یابی تصویر گرافیکی توسط مغز انسان صورت می گیرد. کمپبل
> [^12]و روبسون[^13] آزمایشهای فیزیک روان را با استفاده از الگوهای
> گوناگون شبکه ای انجام داده اند. آنها عنوان کرده اند که سیستم بینایی،
> تصویر را به تصاویر فیلتر شده با فرکانس ها و جهت گیری های مختلف تفکیک
> می کند. والویز [^14]بر روی مغز میمون macaque که بنا به نظر بعضی
> دانشمندان در فرایند بینایی شبیه به مغز انسان است، مطالعاتی را انجام
> داده است. او پاسخ سلول های ساده را در قشر بینایی میمون در فرکانس ها و
> جهت های سینوسی ثبت کرد و نتیجه گرفت که این سلول ها بازه های کوچک
> فرکانس و جهت را می پذیرند. این مطالعات، پژوهشگران حوزه بینایی را به
> رویکردهای فیلتر چندکاناله در تحلیل بافت متمایل کرده است.

2.  \
    []{#_Toc335208982 .anchor}کاربردهای تحلیل بافت

    4.  []{#_Toc209236405 .anchor}مقدمه

> روش های تحلیل بافت در گستره وسیعی از کاربردها مورد استفاده قرار گرفته
> است. در ادامه به اختصار به مرور نقش بافت در معاینه خودکار، پردازش
> تصویر پزشکی، پردازش اسناد و سنجش از دور خواهیم پرداخت. تصاویر مورد
> استفاده در دو حوزه کاربردی پردازش تصویر در شکل زیر نشان داده شده است.
> نقشی که بافت در این حوزه ها پیدا می کند، بسته به کاربرد متفاوت است. به
> عنوان مثال در تصاویر ماهواره ای (قسمت b و c) بافت برای ناهمگونی محلی
> صحنه و این ویژگی برای دسته بندی بافت هایی چون آب، زمین های کشاورزی و
> \... مورد استفاده قرار می گیرد. برای تصویر سونوگرافی قلب در قسمت a
> بافت به صورت توزیع تصادفی المانها شکل گرفته که میزان تصادفی بودن در
> مرز بین حفره قلب و دیواره درونی نسبت به حفره حاوی خون کمتر است. این
> حقیقت می تواند برای بهتر کردن قطعه قطعه سازی و یافتن مرزها با استفاده
> از روش های تحلیل بافت مورد استفاده قرار گیرد.

![](media/image5.png){width="4.995966754155731in"
height="3.899082458442695in"}

3.  []{#_Toc335208182 .anchor}نمونه هایی از حوزه های کاربردی که تحلیل
    بافت در آنها اهمیت پیدا می کند.(a) تصاویر پزشکی از قلب. (b و c)
    نمونه هایی از تصاویر فضایی گرفته شده توسط حسگرهای SAR

<!-- -->

5.  []{#_Toc335208984 .anchor}وارسی هوشمند

> تعداد محدودی از کاربردهای پردازش بافت به مسائل بازرسی تعلق دارد. این
> کاربردها شامل یافتن نقص ها در تصاویری از پارچه ها و وارسی خودکار فرش و
> نقاشی اتومبیل ها می باشد.
>
> در یافتن نقص های موجود در تصاویر بافتی بیشتر کاربردها در حوزه وارسی
> پارچه است. دویل[^15] از روش های پردازش سیگنال برای یافتن نقص های نقطه
> ای و یا خطی در تصاویر بافتی استفاده کرد. این روش ها از ماسک های چرخشی
> کم پشت که در آن مجموعه ای از فیلترها متناسب با تصویر مورد تحلیل انتخاب
> می شود، استفاده می کنند. ویژگی های بافتی از تصاویر فیلتر شده استخراج
> می شود. برای دسته بندی نواحی معیوب از یک دسته بند با فاصله Mahanolobis
> استفاده می شود. چتوریکوف[^16] یک پنجره ساده عملگر تمییز را برای ویژگی
> های بافتی به دست آمده از فیلترینگ، معرفی کرد.چن[^17] و جین[^18] یک
> رویکرد ساختاری را برای یافتن نقص ها در تصاویر بافتی اتخاذ کردند. آنها
> ساختارهای استخوانی را از تصاویر بیرون می کشیدند و با یافتن آنومالی در
> ویژگی های آماری ثابت در این استخوان ها نقص های موجود در بافت را تعیین
> می کردند.کُنرز[^19] روش های تحلیل بافت را برای یافتن نقص ها در الوار
> چوبی به شکل خودکار، به کار برد. یافتن نقص ها با تقسیم تصویر به
> زیرپنجره ها و دسته بندی هر زیرپنجره به یکی از دسته های نقص مثل گره،
> پوسیدگی، رگه های معدنی و \... امکان پذیر می باشد. ویژگی هایی که آنها
> برای انجام این دسته بندی مورد استفاده قرار دادند، بر اساس درجه
> تیرگی[^20] بنا شده بود. از جمله این ویژگی ها می توان به میانگین،
> واریانس، انحراف و اوج سطوح تیرگی اشاره کرد. ترکیب ویژگی های تونی[^21]
> با ویژگی های بافتی نرخ صحت دسته بندی را نسبت به حالتی که یکی از این
> دسته ویژگی ها را به کار ببریم، ارتقاء می بخشد.

در حوزه کنترل کیفیت تصاویر بافتی سیو[^22] روشی را برای ارزیابی سطح فرش
ها پیشنهاد داد. او از ویژگی های بافتی ساده که از آماره های وابستگی دسته
دوم و نیز آماره های اختلاف درجه تیرگی دسته اول، به دست می آید، استفاده
کرد. او نشان داد که ویژگی های بافتی عددی به دست آمده از این روش ها در
توصیف بافت فرش ها موفق هستند. جین از ویژگی های بافتی حاصل از مجموعه ای
از فیلتر های گابور[^23] برای دسته بندی خودکار سطوح نقاشی شده برّاق
استفاده کرد.

6.  []{#_Toc335208985 .anchor}تحلیل تصاویر پزشکی

> روش های تحلیل تصویر، نقش مهمی را در چندین کاربرد پزشکی ایفا می کنند.
> در حالت کلی، کاربردها شامل استخراج خودکار ویژگی ها از تصاویر است که در
> مرحله بعدی برای وظایف گوناگون دسته بندی مثل تشخیص بافت نرمال از بافت
> غیر نرمال مورد استفاده قرار می گیرد. بر اساس وظایف خاص دسته بندی،
> ویژگی های به دست آمده، صفات مورفولوژیکی[^24]، صفات مربوط به رنگ و یا
> صفات بافتی خاص تصویر را به دست می آورد.
>
> هارم[^25] بافت تصاویر را در ترکیب با ویژگی های رنگی برای تشخیص بیماری
> لوسمی بدخیم در نمونه هایی از سلول های خونی تیره به کار برد. او ریزیال
> های بافت و بافت واره های بین این ریزیال ها را استخراج کرد. این بافت
> واره ها ناحیه هایی با رنگ تقریباً یکنواخت هستند. او تعدادی از ویژگی
> های بافت را از بافت واره های شامل تعداد کل پیکسل های درون بافت واره که
> دارای رنگی خاص، میانگین شعاع بافت واره و اندازه بافت واره هستند، به
> دست آورد. ویژگی های بافت در ترکیب با رنگ به وضوح نرخ صحت دسته بندی
> انواع سلول های خونی را در مقایسه با حالت فقط متکی به رنگ، ارتقاء می
> بخشند.
>
> لندویرد[^26] و ژلسما[^27] آماره های گوناگون دسته اول(مثل میانگین شدت
> تیرگی در یک ناحیه) و نیز آماره های دسته دوم (نظیر ماتریس تکرار شدت
> تیرگی) را برای تفکیک انواع مختلف گلبول های سفید محاسبه کردند.
> اینسانا[^28] ویژگی های بافتی را در تصاویر سونوگرافی به کار برد تا
> پارامتر های پراکندگی بافت را تخمین بزند. او کاربرد حائز اهمیتی را از
> دانش درباره فیزیک فرایند تصاویر سونوگرافی و ویژگی های بافت برای طراحی
> مدل بافت ایجاد کرد. چن[^29] از ویژگی های فراکتالی بافت ها برای دسته
> بندی تصاویر سونوگرافی از کبدها بهره جست.
>
> لاندرولد[^30] از ویژگی های فراکتالی بافت در ترکیب با سایر ویژگی های
> بافتی برای تحلیل تصاویر سونوگرافی از قلب استفاده کرد. تصاویر سونوگرافی
> در این مطالعه دنباله ای از تصاویر متوالی از بطن چپ قلب هستند. بافت به
> عنوان اندیسی در هر پیکسل بیان می شود که ابعاد فراکتال محلی در آن، یک
> پنجره $11 \times 11$ بر اساس مدل حرکت براونین[^31] تخمین زده شده است.
> انتظار می رود ابعاد فراکتالی در حالت میانگین در خون نسبت به بافت به
> خاطر نویز و ویژگی های پراکندگی خون بالاتر باشد. زیرا نسبت به حالت جامد
> بی نظم تر است. علاوه بر این ابعاد فراکتال در سطوح خون و بافت تصادفی با
> توجه به اطلاعات یالها نسبتاً کمتر است.

7.  []{#_Toc335208986 .anchor}پردازش اسناد

> یکی از کاربردهای مفید ماشین بینایی و تحلیل تصاویر در حوزه تحلیل تصاویر
> سندی و تشخیص کاراکترهاست. پردازش اسناد دارای حوزه کاربرد وسیعی از
> تشخیص آدرس پستی گرفته تا تحلیل و ترجمه نقشه ها می باشد. در بسیاری از
> برنامه های کاربردی پردازش اسناد پستی (مثل تشخیص اطلاعاتی چون آدرس و کد
> پستی بر روی نامه ها)، اولین گام امکان جدا کردن نواحی شامل اطلاعات مفید
> از زمینه است.
>
> بیشتر روش های تحلیل تصاویر که در حوزه پردازش اسناد به کار می روند،
> مبتنی بر ویژگی های اسناد چاپی هستند و تلاش می کنند تا این ویژگی ها را
> بهتر نمایند. به عنوان مثال روزنامه های رایج به صورت نواحی مستطیل شکل
> سازماندهی شده اند و این حقیقت در الگوریتم های جداسازی استفاده می شود.
> بسیاری از روش ها با الگوریتم های دقیقی بر روی تصاویر کار می کنند که
> اغلب از ویژگی های مورفولوژیکال بهره می جویند. به عنوان مثال ونگ[^32] و
> سریهاری [^33]از مشخصات تصویر مقادیر پیکسل ها برای تشخیص بلوک های متن
> بزرگ با استفاده از یافتن شیارها استفاده کرده اند. وال [^34]از اجرای با
> طول محدود و تحلیل بخش های متصل به هم برای یافتن بلوک های متنی استفاده
> کرد. فلچر[^35] و کاستوری [^36]با استفاده از این واقعیت که بیشتر بلوک
> های متنی در یک خط مستقیم قرار می گیرند و با استفاده از تکنیک های تبدیل
> هاف موفق به یافتن المان های واقع در یک خط شدند. تکست[^37] به مساله
> تشخیص قسمت های چاپی در تصاویر اسناد به عنوان یک مساله دسته بندی با دو
> کلاس نگاه کرد که دسته ها شامل دسته چاپی و دسته پس زمینه هستند. آنها
> روش های متعدد دسته بندی را برای تحقق به جدا سازی متن از زمینه آزمودند.
>
> همچنین روش های جداسازی بافت می تواند در پیش پردازش تصاویر اسناد برای
> تشخیص نواحی مطلوب به کار گرفته شود. به عنوان مثال یکی از کاربردهای
> الگوریتم های جداسازی بافت بیرون کشیدن تصاویر موجود در روزنامه ها می
> باشد. در جداسازی حاصل، یکی از نواحی با بافتی یکنواخت و متفاوت با بافت
> های پیرامون شناسایی می شود. روشی مشابه نیز در تعیین مکان بلوک های متنی
> در روزنامه ها به کار می رود. جداسازی یک سند تصویری با استفاده از سه
> کلاس به دست می آید: یک کلاس برای نواحی متنی، کلاس دوم برای نواحی
> یکنواخت که پس زمینه را شکل می دهند و یا تصاویری که شدت تیرگی در آنها
> به آرامی تغییر می کند؛ و کلاس سوم برای نواحی انتقالی بین دو نوع ناحیه
> در تصویر. نواحی متنی به وسیله تکرار زیاد محتوایشان تشخیص داده می شوند.

8.  []{#_Toc335208987 .anchor}سنجش از دور

> تحلیل بافت به طور گسترده در دسته بندی تصاویری که از راه دور گرفته شده
> اند، به کار می رود. دسته بندی سطوح زمانی که نواحی همگون با زمینه های
> مختلف (مثل گندم، سطوح آب، نواحی شهری و \...) نیاز به شناسایی دارند یک
> کاربرد بسیار مهم است. هارالیک[^38] ویژگی های همبستگی سطوح تیرگی را
> برای تحلیل تصاویر از دور گرفته شده به کار برد. او ماتریس تکرار سطوح
> تیرگی را برای فاصله یک در چهار جهت (0^0^، 45^0^، 90 ^0^و135^0^) محاسبه
> کرد. برای یک مساله دسته بندی با 7 کلاس، به دقت تقریبی 80% در با
> استفاده از ویژگی های بافتی دست یافت.
>
> ریگنات[^39] وکواک[^40] تصاویر SAR را با استفاده از ویژگی های به دست
> آمده از ماتریس تکرار سطوح تیرگی مورد تحلیل قرار دادند. آنها این ویژگی
> ها را با پیش زمینه ای که نسبت به تصاویر SAR داشتند، به دست آوردند. به
> عنوان مثال الگوریتم های بازیابی تصاویر را برای حذف نویز های ذاتی در
> تصاویر SAR مورد استفاده قرار دادند تا نتایج دسته بندی را بهبود بخشند.
> استفاده ویژگی های مختلف در تحلیل تصاویر SAR توسط شیستاد[^41] و
> جین[^42] صورت پذیرفت. ابعاد فراکتالی، مدل خودپیشروی فیلد تصادفی
> مارکوف[^43] و ماتریس تکرار ویژگی های بافتی در دسته بندی مورد استفاده
> قرار گرفت. خطای دسته بندی از مقدار 25 درصد برای مدل های فراکتالی تا
> مقدار 6 درصد برای ویژگی های MRF متغیر بوده است.

3.  \
    []{#_Toc335208988 .anchor}روش های تحلیل بافت و استخراج ویژگی های
    بافتی

    9.  []{#_Toc209236409 .anchor}مقدمه

> تشخیص جنبه های درک شده از بافت در یک تصویر، اولین گام مهم در راستای
> ایجاد یک مدل ریاضی برای بافت است. تغییرات شدت در یک تصویر که مشخص
> کننده بافت آن است عمدتاً وابسته به پاره ای از تغییرات فیزیکی بر روی
> این تصاویر است. مدل کردن این تغییرات فیزیکی بسیار دشوار است؛ به همین
> دلیل معمولاً بافت توسط تغییرات دوبعدی شدت در تصویر مشخص می شود. این
> امر، موجب آشکار شدن این حقیقت می شود که بافت تعریف دقیق و کلی ندارد.
> البته تعدادی از ویژگی های عنوان شده برای بافت معمولاً صحیح فرض می شود.

-   بافت یک ویژگی برای نواحی موجود در تصویر است و بافت یک نقطه، تعریف
    نشده است؛ بنابراین بافت، یک ویژگی وابسته به متن است و تعریف آن باید
    شامل سطوح تیرگی در یک همسایگی فضایی باشد. اندازه این همسایگی بستگی
    به نوع بافت و یا اندازه عناصر بنیادین تشکیل دهنده آن دارد.

-   بافت شامل توزیع فضایی سطوح تیرگی است. بنابراین هیستوگرام دوبعدی یا
    ماتریس تکرار، ابزارهای منطقی برای تحلیل بافت می باشند.

-   بافت در یک تصویر می تواند در ابعاد یا سطوح متفاوت رزولوشن به دست
    آید. به عنوان مثال، بافت موجود بر روی سطح یک دیوار آجری را در نظر
    بگیرید. در یک رزولوشن پایین، عناصر تشکیل دهنده دیوار، بلوک های آجری
    روی سطح آن هستند. اما در رزولوشن های بالاتر جزئیات عناصر تشکیل دهنده
    بلوک های آجری نیز به عنوان بافت دیوار درنظر گرفته می شود.

-   زمانی یک ناحیه در یک تصویر دارای بافت است که تعداد اشیای بنیادین
    تشکیل دهنده آن ناحیه نسبتاً زیاد باشد. اگر تعداد این عناصر بنیادین
    در یک ناحیه کم باشد، به جای اینکه بافت آن ناحیه دریافت شود، گروهی از
    اشیای شمارش پذیر دریافت می شود.

> بافت تصویر دارای تعدادی جنبه های دریافتی است که نقش مهمی را در توصیف
> بافت ایفا می کنند. بعضی از ویژگی هایی که در توصیف بافت بسیار مؤثرند
> عبارتند از: یکنواختی[^44]، تراکم[^45]، زبری[^46]، سفتی[^47]، نظم[^48]،
> خطی بودن[^49]، جهت دار بودن[^50]، فرکانس[^51] و فاز[^52]. بعضی از این
> ویژگی ها مستقل نیستند. به عنوان مثال فرکانس نسبت به ظرفیت و جهت مستقل
> نیست. این حقیقت که مفهوم بافت دارای چنین ابعاد گسترده ای است دلیلی است
> بر اینکه تنها یک روش برای ارائه و مشخص سازی بافت کافی نیست.

10. []{#_Toc335208990 .anchor}روش های آماری

> یکی از ویژگی های کیفی بافت، توزیع فضایی مقادیر تیرگی است. به همین دلیل
> روش های آماری یکی از اولین رویکردها در حوزه ماشین بینایی بوده است. در
> همین راستا ما از مجموعه
> $\left\{ I\left( x,y \right),\ \ 0 \leq x \leq N - 1,\ \ 0 \leq y \leq N - 1 \right\}$
> برای معادل سازی یک تصویر $N \times N\ $ با $G$ سطح تیرگی استفاده می
> کنیم. تعداد زیادی ویژگی بافتی پیشنهاد داده شده است اما همان طور که ذکر
> شد همه این ویژگی ها الزاماً مستقل نیستند. رابطه بین ویژگی های متعدد
> آماری مربوط به بافت در شکل 3-1 نمایش داده شده است. همچنین پیکارد[^53]
> ماتریس تکرار سطوح تیرگی را به مدل MRF ارتباط داده است.

![](media/image6.png){width="4.606692913385827in"
height="2.7522933070866142in"}

4.  []{#_Toc335208184 .anchor}وابستگی ویژگی های آماری بافت

<!-- -->

1.  []{#_Toc335208991 .anchor}**ماتریس تکرار**

وابستگی فضایی سطوح تیرگی، ویژگی های وابسته به آماره های دسته دوم تصویر
را تخمین می زند. هارالیک استفاده از ماتریس تکرار را برای اولین بار
پیشنهاد داد که این روش امروزه یکی از شناخته شده ترین و پر استفاده ترین
روش های استخراج ویژگی های بافتی است. ماتریس تکرار سطوح تیرگی
$G \times G$ با نام $p_{d}$ برای بردار$d = (d_{x},d_{y})$ بدین شکل تعریف
می شود: درایه $(i,j)$ از ماتریس $p_{d}$ تعداد تکرار جفت مقادیر $i$ و$j$
با فاصله $d$ در سطوح تیرگی تصویر است. تعریف ریاضی این ماتریس به شکل زیر
است:

$$p_{d}\left( i,j \right) = \left| \left\{ \left( \left( r,s \right),\left( t,v \right) \right):I\left( r,s \right) = i,I\left( t,v \right) = j \right\} \right|$$

که در آن $\left( r,s \right),\left( t,v \right) \in N \times N$ و
$\left( t,v \right) = (r + d_{x},s + d_{y})$ و $\left| . \right|$
کاردینالیتی[^54] مجموعه است.

به عنوان مثال، ماتریس 4\*4 زیر با 3 مقدار تیرگی متفاوت را در نظر بگیرید:

$$\begin{bmatrix}
1 & 1 & \begin{matrix}
0 & 0 \\
\end{matrix} \\
1 & 1 & \begin{matrix}
0 & 0 \\
\end{matrix} \\
\begin{matrix}
0 \\
0 \\
\end{matrix} & \begin{matrix}
0 \\
0 \\
\end{matrix} & \begin{matrix}
\begin{matrix}
2 \\
2 \\
\end{matrix} & \begin{matrix}
2 \\
2 \\
\end{matrix} \\
\end{matrix} \\
\end{bmatrix}$$

ماتریس تکرار 3\*3 سطوح تیرگی برای این تصویر برای بردار جانشینی
$d = (1,0)$ به شکل زیر به دست می آید:

$$P\text{d\ } = \begin{bmatrix}
4 & 0 & 2 \\
2 & 2 & 0 \\
0 & 0 & 2 \\
\end{bmatrix}$$

درایه $(0,0)$ از ماتریس $p_{d}$ مقدار 4 گرفته زیرا چهار جفت پیکسل در
ماتریس اصلی وجود دارد که مجاورت افقی (در راستای بردار $(1,0)$) دارند و
مقادیر آنها صفر است. همان طور که مشاهده می کنید، ماتریس تکرار به دست
آمده متقارن نیست اما با یک تغییر در تعریف این ماتریس می توان به یک
ماتریس متقارن رسید:

$$p = p_{d} + p_{- d}$$

ماتریس تکرار ویژگی های قابل اتکایی را درباره توزیع فضایی سطوح تیرگی در
بافت تصویر به دست می دهد. به عنوان مثال اگر بیشتر درایه های ماتریس تکرار
در راستای قطر متمرکز شوند، بافت در راستای بردار تناظر d، زبر می باشد.
هارالیک تعدادی ویژگی بافتی مفید را که از ماتریس تکرار قابل محاسبه است
معرفی کرد. در ادامه بعضی از پرکاربردترین این ویژگی ها آورده شده است:

1.  Angular Second Moment :

$$f_{1} = \sum_{i}^{}{\sum_{j}^{}\left\{ p(i,j) \right\}^{2}}$$

2.  Contrast :

$$f_{2} = \sum_{n = 0}^{N_{g - 1}}{n^{2}\left\{ {\sum_{i = 1}^{N_{g}}{\sum_{j = 1}^{N_{g}}{p(i,j)}}}_{\left| i - j \right| = n} \right\}}$$

3.  Correlation :

$$f_{3} = \frac{\sum_{i}^{}{\sum_{j}^{}{\left( \text{ij} \right)p\left( i,j \right) - \mu_{x}\mu_{y}}}}{\sigma_{x}\sigma_{y}}$$

4.  Variance (Sum of Squares):

$$f_{4} = \sum_{i}^{}{\sum_{j}^{}{\left( i - \mu \right)^{2}p(i,j)}}$$

5.  Inverse Difference Moment:

$$f_{5} = \sum_{i}^{}{\sum_{j}^{}{\frac{1}{1 + \left( i - j \right)^{2}}p(i,j)}}$$

6.  Sum Average :

$$f_{6} = \sum_{i = 2}^{2N_{g}}{ip_{x + y}(i)}$$

7.  Sum Variance :

$$f_{7} = \sum_{i = 2}^{2N_{g}}{\left( i - f_{8} \right)^{2}p_{x + y}(i)}$$

8.  Sum Entropy :

$$f_{8} = - \sum_{i = 2}^{2N_{g}}{p_{x + y}\left( i \right)\text{\ log}\left\{ p_{x + y}(i) \right\}}$$

9.  Entropy :

$$f_{9} = - \sum_{i}^{}{\sum_{j}^{}{p\left( i,j \right)\log{(p\left( i,j \right))}}}$$

10. Difference Variance :

$$f_{10} = var(p_{x - y})$$

11. Difference Entropy :

$$f_{11} = - \sum_{i = 0}^{N_{g} - 1}{p_{x - y}\left( i \right)\log\left\{ p_{x - y}(i) \right\}}$$

12و13- معیارهای به دست آمده از همبستگی:

$$f_{12} = \frac{HXY - HXY1}{max\{ HX,HY\}}$$

$$f_{13} = \sqrt{1 - e^{- 2\left( HXY2 - HXY \right)}}$$

که در آن

$$HXY = - \sum_{i}^{}{\sum_{j}^{}{p\left( i,j \right)\left( logp\left( i,j \right) \right)}}$$

$$HXY1 = - \sum_{i}^{}{\sum_{j}^{}{p\left( i,j \right)\left\{ logp_{x}\left( i \right)p_{y}\left( j \right) \right\}}}$$

$$HXY2 = - \sum_{i}^{}{\sum_{j}^{}{p_{x}\left( i \right)p_{y}\left( j \right)\log\left\{ p_{x}(i)p_{y}(j) \right\}}}$$

14- Maximal Correlation Coefficient :

$$f_{14} = \sqrt{(Second\ largest\ eigenvalue\ of\ Q)}$$

که در آن

$$Q\left( i,j \right) = \sum_{k}^{}\frac{p\left( i,k \right)p(j,k)}{p_{x}(i)p_{y}(k)}$$

ویژگی های به دست آمده از ماتریس تکرار از چند مشکل تأثیر می پذیرند. هیچ
روش مناسبی برای انتخاب بردار $d$ و محاسبه ماتریس تکرار برای مقادیر مختلف
$d$ وجود ندارد. برای بردار $d$ تعداد زیادی از ویژگی ها با استفاده از این
ماتریس قابل محاسبه هستند. این بدین معنی است که تعدادی از روش های انتخاب
ویژگی باید برای انتخاب مناسب ترین ویژگی ها به کار گرفته شود. ویژگی های
بافتی مبتنی بر ماتریس تکرار عمدتاً در مسائل دسته بندی بافت های گوناگون
استفاده می شود و در زمینه جداسازی[^55] بافت های یک تصویر کاربردی ندارد.

-   ماسک مکعبی در استخراج ویژگی های بافت

یافتن جزئیات ممکن در فضای سه بعدی موضوعی رایج در بافت های جامد نظیر سنگ
ها، کریستال ها و مواد معدنی به شمار می آید. این روش ها الگوهای تکراری سه
بعدی در آرایش اتم ها، یون ها و یا مولکول هایشان را مورد توجه قرار می
دهند که می توانند بر اساس تقارن و یا هندسه سلول های پایه ای شان دسته
بندی شوند. دسته بندی دو بعدی یک شبکه رقمی از دسته بندی سه بعدی دشوارتر
است. در پردازش تصویر، فضای سه بعدی وحتی فضاهای بالاتر مورد علاقه قرار
گرفته اند. در تصاویر سه بعدی پیکسل ها به وُکسل[^56] ها تبدیل می شوند.
وکسل نمایانگر مقدار یک المان است. وکسل بیانگر یک الگوی بنیادی ترکیبی بر
روی فضای سه بعدی است. روابط همسایگی در سه جهت بسیار پیچیده تر است. سه
راه برای تعریف همسایه وجود دارد: وکسل های متصل به وجوه، وکسل های متصل به
یال ها و وکسل های متصل به رئوس. در ادامه یک شمای کلی از الگوی مکعبی بر
فضای دوبعدی را که یک وکسل را با رئوس متصل از فضای سه بعدی بیان می کند،
معرفی می کنیم.

بر روی یک ماسک مکعبی میلیون ها الگوی ترکیبی وجود دارد که تعیین کننده یک
ظرفیت است. بنابراین چنین امکانی وجود ندارد که همه این الگوها را برای
دسته بندی و تشخیص بافت ها تحلیل کرد. برای حل این مشکل فقط پنج الگوی
ترکیبی را بر روی یک ماسک مکعبی به منظور تشخیص بافت در نظر می گیریم:

1.  الگویی که در آن تمام وجوه مکعب دارای مقدار صفر هستند. (ZVSP)

2.  الگویی که در آن تمامی وجوه دارای مقدار یک هستند (CVSP)

> 3 تا 5- الگویی که در آن تمام یک ها در یک سمت مکعب هستند که ظرفیت یک
> سوی مکعب را بیان می کنند: وجه جلو (FVSP)، وجه چپ (LVSP) و وجه راست
> (RVSP)

در مطالعه حاضر یک SVP بر روی ماسک مکعبی فقط شامل الگوهای WVSP، SVSP،
LVLP و RVSP می باشد. در تصاویر زیر حرف d بیانگر حالت بی اهمیت است که می
تواند اگوی روزنه و یا ذره باشد.

![](media/image7.png){width="5.339449912510936in"
height="2.843558617672791in"}

5.  []{#_Toc335208186 .anchor}ماسک های مکعبی مورد استفاده در مدل کردن
    بافت در همسایگی های نسبتاً بزرگ

<!-- -->

2.  []{#_Toc334914802 .anchor}ویژگی های مربوط به هبستگی[^57]

یک ویژگی مهم بسیاری از بافت ها، طبیعت تکرار و جانشینی المان های بافتی در
تصویر است. تابع همبستگی یک تصویر می تواند برای دستیابی به میزان نظم و
نیز نرمی و سختی بافت موجود در تصویر به کار رود. تابع همبستگی تصویر
$I(x,y)$ به شکل زیر تعریف می شود:

$$\rho\left( x,y \right) = \frac{\sum_{u = 0}^{N}{\sum_{v = 0}^{N}{I\left( u,v \right)I(u + x,v + y)}}}{\sum_{u = 0}^{N}{\sum_{v = 0}^{N}{I^{2}(u,v)}}}$$

این تابع به اندازه المان های بنیادین بافت وابسته است. اگر بافت خشن باشد
تابع همبستگی به آرامی نزول می کند؛ در غیر این صورت، خیلی سریع نزول می
کند. برای بافت های منظم تابع همبستگی قله ها و دره ها را بیان می کند.

همچنین تابع همبستگی به طیف توان تبدیل فوریه وابسته است( به شکل 1-3 که
رابطه بین روشها را معرفی می کرد مراجعه نمایید). فرض کنیم تابع تصویر در
دامنه فضایی $I(x,y)\ $ باشد و تبدیل فوریه آن $F(u,v)$ باشد. مقدار
${|F(u,v)|}^{2}$ به عنوان طیف توان معرفی می شود که \|.\| در آن نماد
اندازه عدد مختلط است. مثال شکل زیر اثر جهت گیری بافت را بر توزیع انرژی
در طیف توان مشخص می سازد.

![](media/image8.png){width="4.7339446631671045in"
height="2.390237314085739in"}

6.  []{#_Toc335208188 .anchor}ویژگی های به دست آمده از طیف توان. (a) یک
    بافت تصویر و (b) طیف توان آن.

رویکردهای جدید که از این ویژگی های طیفی استفاده می کنند، دامنه فرکانس را
به حلقه ها(در حوزه فرکانس) و محور ها (در حوزه جهت) تقسیم می کند.

![](media/image9.png){width="4.835932852143482in"
height="2.3027515310586177in"}

7.  []{#_Toc335208190 .anchor}تقسیم دامنه فرکانس به حلقه ها و محورها

بنابراین در حوزه فرکانس، انرژی کل به حلقه ها تقسیم می شود و هر کدام از
نواحی به عنوان ویژگی بافتی محاسبه می شوند.

11. []{#_Toc335208993 .anchor}روش های هندسی

دسته دیگری از روش های تحلیل بافت که از آنها تعبیر به روش های هندسی می
شود بافت را به صورت ترکیبی از المان های ساختاری یا المان های بنیادین
بافتی تعریف می کنند. هنگامی که المان های بافتی در یک تصویر مشخص شد، دو
رویکرد کلی برای تحلیل بافت وجود دارد. رویکرد اول ویژگی های آماری را از
المان های استخراج شده محاسبه می کند و آنها را به عنوان ویژگی های بافتی
مورد استفاده قرار می دهد. رویکرد دوم به جستجوی قانون جانشینی المان های
بافتی توصیف کننده بافت می پردازد. این رویکرد ممکن است شامل روش های هندسی
یا ترکیبی در تحلیل بافت باشد.

3.  []{#_Toc334914804 .anchor}ویژگی های موزائیک بندیvoronoi

تسریان[^58] و جین[^59] استخراج علامت[^60] های بافت را با استفاده از خواص
موزائیک بندیvoronoi برای تصاویر داده شده مطرح کردند. موزائیک بندیvoronoi
به خاطر ویژگی های مناسبش برای تعریف همسایگی محلی فضایی مورد توجه قرار
گرفت. زیرا توزیع فضایی محلی علامت ها به صورت چند ضلعی های voronoi منعکس
می شوند. در ابتدا علامت های بافت استخراج می شوند و سپس موزائیک بندی
ساخته می شود. علامت ها می توانند به سادگی سایه روشن در تصویر و یا به
پیچیدگی ساختارهایی مثل اجزای خطی یا مرزهای بسته باشند.

در ماشین بینایی، موزائیک بندیvoronoi ابتدا توسط آهجوا[^61] به عنوان مدلی
برای تعریف همسایگی مطرح شد. فرض کنید مجموعه $S$ با سه علامت یا بیشتر در
فضای اقلیدسی داده شده است. (برای سادگی فرض می کنیم که علامت یک نقطه
است). فرض کنید تمام این نقاط در یک خط نیستند و هیچ چهار نقطه ای بر روی
یک دایره نیستند. دو نقطه دلخواه $P$ و $Q$ را در نظر بگیرید. خط نیمسازی
که $P$ و $Q$ را به هم مرتبط می کند، مکان هندسی نقاطی است که دارای مسافت
مساوی از $P$ و $Q$ هستند و صفحه را به دو نیمه تقسیم می کنند. نیم صفحه
$H_{P}^{Q}$ مکان هندسی نقاطی است که به $P$ نزدیکترند تا به $Q$. برای هر
نقطه داده شده $P$، مجموعه ای از چنین نیم صفحه هایی برای انتخاب های
گوناگون $Q$ به دست می آید. عبارت اشتراکی
$\prod_{Q \in S\ ,\ Q \neq P}^{}H_{P}^{Q}$ مکان یک ناحیه چندضلعی را
تعریف می کند که شامل نقاطی می شود که به $P$ نزدیکترند تا به سایر نقاط.
چنین ناحیه ای را چند ضلعی voronoi متناظر با یک نقطه می گویند. مجموعه
کامل چندضلعی های voronoi را نمودار voronoi مجموعه S می نامند. نمودار
voronoi به همراه چندضلعی های ناقص در پوسته محدب، یک موزائیک بندیvoronoi
از کل صفحه را نتیجه می دهد. دو نقطه را همسایه voronoi یکدیگر گوییم اگر
چند ضلعی های voronoi شامل آنها یک یال مشترک داشته باشند. حاصل انجام
دوگانه موزائیک بندیvoronoi ، گرافی است که با اتصال همه جفت نقاطی که در
همسایگی voronoi قرار دارند، به دست می آید.

همسایگی علامت$p$ توسط چندضلعی voronoi شامل $p$ تعریف می شود. بسیاری از
خصوصیات واضح محیط یک علامت، آشکار کننده ویژگی های هندسی همسایگی voronoi
می باشد. ویژگی های هندسی چندضلعی های voronoi به عنوان ویژگی های بافت
مورد استفاده قرار می گیرند.

![](media/image10.png){width="4.614583333333333in"
height="2.4402777777777778in"}

8.  []{#_Toc335208192 .anchor}موزائیک بندی voronoi . تصویر (a) نمونه ای
    از الگوی نقطه ای و تصویر (b) موزائیک بندی voronoi برای آن.

برای اعمال روش های هندسی بر تصاویر سطح خاکستری ابتدا باید علامت ها را از
تصاویر استخراج کنیم. ما از الگوریتم ساده ای که در ادامه آمده است برای
استخراج علامت ها از تصاویر سطح خاکستری ورودی استفاده می کنیم:

1.  اعمال فیلتر لاپلاسی گاوسی (LoG یا$\nabla^{2}G$). برای کارایی
    محاسباتی فیلتر $\nabla^{2}G$ را می توان با تفاضل فیلترهای گاوسی
    تخمین زد(DoG). اندازه فیلتر DoG با استفاده از اندازه دو فیلتر گاوسی
    به دست می آید. توسریان و جین از $\sigma_{1} = 1$ برای اولین فیلتر
    گاوسی و از $\sigma_{2} = 1.6\  \times \sigma_{1}$ برای دومین فیلتر
    گاوسی استفاده کردند.

2.  انتخاب پیکسل هایی که بر روی یک بیشینه محلی درجه تیرگی در تصویر فیلتر
    شده قرار گرفته اند. یک پیکسل در یک تصویر فیلتر شده بر روی بیشینه
    محلی قرار دارد اگر اندازه آن از 6 بیشتر باشد یا اینکه از هر هشت
    همسایه نزدیک خود بزرگتر باشد. به عنوان مثال، اعمال گام های 1 و 2 بر
    روی قسمت a از تصویر زیر آن را به شکل b در آورده است.

    ![](media/image11.png){width="4.747767935258093in"
    height="2.955181539807524in"}

    9.  []{#_Toc335208194 .anchor}جداسازی بافت های تصویر با استفاده از
        موزائیک بندی voronoi. تصویر (a) مثالی از دو بافت در یک تصویر.
        تصویر (b) اوج های یافته شده از تصویر فیلترشده. تصویر (c) جداسازی
        بافت با استفاده از ویژگی های بافتی به دست آمده از موزائیک بندی
        voronoi

3.  انجام یک تحلیل بخش های پیوسته بر روی تصویر دودویی با استفاده از هشت
    همسایه نزدیک آن. هر بخش پیوسته یک عنصر بنیادین بافت را مشخص می کند
    که همان علامت است.

> در نهایت، موزائیک بندیvoronoi ِ علامت های به دست آمده ساخته می شود.
> ویژگی های هر سلول voronoi استخراج می شود و علامت های با ویژگی های
> مشابه برای ساختن نواحی بافتی یکنواخت گروه بندی می شوند. گشتاور نواحی
> چندضلعی های voronoi مجموعه ای از ویژگی های مفید که منعکس کننده توزیع
> فضایی و شکل علامت در بافت تصویر است را فراهم می آورد. گشتاورهای مرتبه
> $(p + q)$ُ م از نواحی بسته $R$ برای علامت با مشخصه های $(x_{0},y_{0})$
> به شکل زیر تعریف می شود:

$$m_{\text{pq}} = \iint_{}^{}{\left( x - x_{0} \right)^{p}{(y - y_{0})}^{q}\text{dxdy}}$$

> که در آن $p + q = 0,1,2,\ldots$ است. یک توصیف از پنج ویژگی مورد
> استفاده در زیر آمده است که در آن ($\overline{x}\ ,\ \overline{y}$)
> مختصات مرکز چندضلعی های voronoi است.
>
> ![](media/image12.png){width="4.788417541557306in"
> height="3.2601990376202976in"}
>
> ویژگی های بافتی مبتنی بر چندضلعی های voronoi در جداسازی[^62] تصاویر
> بافتی مورد استفاده قرار می گیرد. الگوریتم جداسازی بر اساس یال ها، با
> استفاده از مقایسه آماری مجموعه علامت های مجاور عمل می کند. یک عدم
> مشابهت بزرگ در میان ویژگی های بافتی یک شاهد برای یال بافت است. این
> الگوریتم تصاویر بافتی سطح خاکستری را با موفقیت جداسازی می کند و نیز
> تعداد بافت های ترکیبی با آماره های دسته دوم یکسان را مشخص می سازد.

4.  []{#_Toc334914805 .anchor}روش های ساختاری

> مدل های ساختاری بافت فرض می کنند که بافت از عناصر بنیادینش تشکیل شده
> است. بافت با جانشینی این عناصر بنیادین بر اساس قوانین جانشینی مشخصی
> تشکیل می شود. این دسته از الگوریتم ها در حالت کلی محدود به بافت هایی
> منظم می شوند. تحلیل ساختاری بافت شامل دو گام می شود: استخراج المان های
> ساختاری بافت و یافتن قانون جانشینی.
>
> راه هایی برای استخراج المان های ساختاری بافت موجود است. لازم است
> بدانیم منظور از المان های ساختاری در اینجا چیست؟ معمولاً المان های
> بافت شامل نواحی ای در تصویر با سطح تیرگی یکنواخت می شوند. وورهیز[^63]
> و پوگیو[^64] معتقدند لکه ها در فهم و انتزاع بافت بسیار حائز اهمیت
> هستند. آنها روشی را بر پایه فیلتر کردن تصویر با ماسک های لاپلاسی و
> گاوسی در ابعاد مختلف و ادغام این اطلاعات برای استخراج لکه ها در تصاویر
> ارائه کردند. بلاستین[^65] و آهوجا فرایندی مشابه را برای استخراج علامت
> های بافت در تصویر با استفاده از آزمایش حاصل فیلتر LoG در ابعاد مختلف
> معرفی کردند. آنها تشخیص لکه چند بعدی خود را با محاسبه شکل سطح به منظور
> بهتر کردن نتایج هر دو فرایند ترکیب کردند. همچنین تومیتا[^66] و تسوجی
> [^67]روشی را برای محاسبه علامت های بافت با اعمال یک تبدیل محور میانی
> بر روی بخش های پیوسته یک تصویر بخش بخش شده پیشنهاد دادند. آنها سپس
> تعدادی از ویژگی ها نظیر شدت و شکل این علامت های یافت شده را محاسبه
> کردند.
>
> زوکر[^68] روشی را پیشنهاد داد که در آن بافت های قابل مشاهده (بافت های
> واقعی) به بافت های نظری متمایل می شوند. قانون جانشینی برای بافت نظری
> با استفاده از گرافی که با یک موزائیک بندی منظم یا نیمه منظم ایزومورف
> است معرفی می شود. این گراف ها سپس برای ساختن بافت قابل مشاهده، تبدیل
> می شوند. این که چه موزائیک های منظمی به عنوان قانون جانشینی به کار می
> رود، بستگی به بافت قابل مشاهده دارد. این امر با محاسبه یک هیستوگرام دو
> بعدی از موقعیت های نسبی علامت های بافتی یافته شده انجام می پذیرد.

رویکرد دیگری برای مدل کردن بافت با ابزارهای ساختاری توسط فو[^69] ارائه
شده است. در این رویکرد بافت تصویر به عنوان المان های بنیادین بافتی که بر
اساس قانون جانشینی سازماندهی شده اند، درنظر گرفته می شود. این المان های
بنیادی می توانند به سادگی یک پیکسل که یک مقدار تیرگی را به خود می گیرد،
باشد؛ اما معمولاً مجموعه ای از پیکسل ها را شامل می شود. قانون جانشینی
توسط یک درخت گرامر به دست می آید. آنگاه بافت به صورت رشته ای در یک زبان
که دارای گرامر خاصی است تجسم می شود. ترم های پایانی این گرامر همان المان
های بنیادی هستند. مزیت این روش این است که می تواند علاوه بر تحلیل بافت
در تولید بافت های جدید مورد استفاده قرار گیرد.

12. []{#_Toc335208996 .anchor}روش های مبتنی بر مدل

> روش های تحلیل بافت مبتنی بر مدل در ابتدا یک مدل برای تصویر ایجاد می
> کند و سپس از این مدل برای توصیف و حتی سنتز تصویر استفاده می کند.
> پارامترهای مدل ویژگی های کیفی اساسی بافت را استخراج می کند.

5.  []{#_Toc334914807 .anchor}مدل فیلدهای تصادفی

> فیلدهای تصادفی مارکوف[^70] در مدل کردن تصاویر بسیار شهرت دارند. این
> مدل ها قادرند اطلاعات متنی محلی را در یک تصویر استخراج کنند. این مدل
> ها با این فرض همراهند که شدت تیرگی در هر پیکسل از تصویر تنها وابسته به
> پیکسل های مجاور است. مدل MRF در برنامه های پردازش تصویر متعددی مانند
> سنتز بافت، دسته بندی بافت، جداسازی تصویر، بازیابی تصویر و فشرده سازی
> تصویر به کار رفته است.
>
> معمولاً تصویر با یک شبکه $N \times N$ که به صورت
> $L = \left\{ \left( i,j \right)|1 \leq i \leq M,\ \ 1 \leq j \leq N \right\}$
> نمایش داده می شود، بیان می گردد.$I(i,j)$ یک متغیر تصادفی است که تعیین
> کننده سطح تیرگی هر پیکسل $(i,j)$ بر روی شبکه $L$ است. برای سهولت در
> محاسبات ریاضی اندیس گذاری شبکه را با $I_{t}$ نمایش می دهیم که در آن
> $t = \left( i - 1 \right)N + j$ می باشد. فرض کنیم $A$ مجموعه ای باشد
> که همه متغیرهای تصادفی $I_{t}$ در آن قرار می گیرند و
> $\pi = \left\{ \left( x_{1},x_{2},\ldots,x_{\text{MN}} \right)|x\epsilon A \right\}$
> نشان دهنده مجموعه همه برچسب های $L$ باشد. لازم به ذکر است که مجموعه
> $A$ بر اساس حوزه کاربرد تعیین می شود. به عنوان مثال برای یک تصویر با
> 256 سطح تیرگی، مجموعه $A$ می تواند $\{ 0,1,2,\ldots,255\}$ باشد. یک
> فیلد تصادفی گسسته مارکوف، یک فیلد تصادفی است که تابع احتمال تجمعی آن
> شامل صفات صراحت[^71]، مارکوفی بودن[^72] و همگونی[^73] می باشد.
>
> مجموعه همسایگی مکان $t$ از راه های مختلفی قابل تعریف است. همسایه های
> مرتبه اول $t$ چهار همسایه متصل به آن هستند. همسایه های مرتبه دوم هشت
> همسایه متصل به آن هستند. در میان این همسایگی ها، مجموعه همسایه هایی که
> دسته ها را شکل می دهند معمولاً در تعریف احتمال های شرطی استفاده می
> شوند.
>
> یک فیلد تصادفی گیبس (GRF) به کل شبکه، یک تابع توزیع تجمعی را تخصیص می
> دهد:

$$P\left( X = x \right) = \frac{1}{Z}e^{- U(x)}\ \ \ \ \ \ \ \forall x \in \mathrm{\Omega}$$

> که در آن $U(x)$ یک تابع انرژی است و $Z$ یک ثابت نرمال سازی است که به
> تابع پارتیشن موسوم است. تابع انرژی معمولاً به صورت دسته هایی که همه
> پیکسل های مجاورت را تشکیل می دهند، تعریف می شود. برای همسایه های مرتبه
> دوم دسته های ممکن در شکل زیر نمایش داده شده است.

![](media/image13.png){width="5.165137795275591in"
height="1.5931364829396326in"}

10. []{#_Toc335208196 .anchor}دسته های ممکن برای همسایگی مرتبه دوم

> سپس تابع انرژی با استفاده از تابع بالقوه $V_{c}$ بر روی دسته Q تعریف
> می شود:

$$U\left( x \right) = \sum_{c \in Q}^{}{V_{C}(x)}$$

> یک ویژگی مهم این سیستم همسایگی این است که برای هر فیلد تصادفی مارکوف،
> یک فیلد تصادفی گیبس منحصر به فرد وجود دارد و برای هر فیلد تصادفی گیبس
> یک فیلد تصادفی مارکوف منحصر به فرد وجود دارد. نتیجه این قضیه این است
> که مدل کردن بافت می تواند از طریق توصیف کل انرژی شبکه و یا مدل کردن آن
> به صورت محلی از طریق توصیف تعاملات محلی پیکسل های مجاور به وسیله
> احتمالات شرطی، صورت پذیرد.
>
> راه هایی برای توصیف تصویر با استفاده از فیلد تصادفی گیبس وجود دارد. در
> بین این راه ها،مدل درین-الیوت[^74] و مدل دوجمله ای خودکار [^75]تنها
> پیکسل مجرد و دسته های دو به دوی پیکسل ها در همسایه های مرتبه دوم یک
> مکان را در نظر می گیرند. در هر دو مدل احتمالات شرطی به شکل زیر تعریف
> می شود:

$$P\left( x_{t} \middle| R_{t} \right) = \frac{1}{Z_{t}}e^{w{(x_{t}|R_{t})}^{T}\theta}$$

> که در آن $Z_{t} = \sum_{g \in A}^{}e^{- w{(g,R_{t})}^{T}\theta}$ ثابت
> نرمال سازی است. انرژی GRF به صورت زیر محاسبه می شود:

$$U\left( x \right) = \frac{1}{2}\sum_{t = 1}^{\text{MN}}{w{(x_{t},R_{t})}^{T}\theta}$$

> که در آن
> $w\left( x_{t},R_{t} \right) = \left\lbrack w_{1}{(x}_{t})w_{2}{(x}_{t})w_{3}{(x}_{t})w_{4}{(x}_{t}) \right\rbrack^{T}$
> و
> $\theta = \left\lbrack \theta_{1}\theta_{2}\theta_{3}\theta_{4} \right\rbrack^{T}$
> . هر دو مدل، اجزای بردار $w$ را مشخص می سازد. $w_{r}(x_{t})$ برای دو
> مدل متفاوت است و به شکل زیر محاسبه می شود:
>
> مدل درین- الیوت :

$$W_{r}\left( X_{t} \right) = I\left( X_{t},X_{t - r} \right) + I\left( X_{t},X_{t + r} \right)\ \ \ \ \ \ \ \ \ \ 1 \leq r \leq 4$$

> مدل دوجمله ای خودکار:

$$W_{r}\left( X_{t} \right) = X_{t}\left( X_{t - r},X_{t + r} \right)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 1 \leq r \leq 4$$

> در اینجا $r$ اندیسی است که مجموعه پیکسل های مجاور را برای مکان $t$
> تعیین می کند و $I(a,b)$ یک تابع علامت به شکل زیر است:

$$I\left( a,b \right) = \left\{ \begin{matrix}
 - 1\ \ \ \ \ \ \ \ \ \ \ \ if\ a = b \\
1\ \ \ \ otherwise \\
\end{matrix} \right.\ $$

> بردار $\theta$ مجموعه ای از پارامترهاست که ویژگی های بافتی تصویر را
> تعریف و مدل می کنند. در مسائل ترکیب بافت، مقادیر برای کنترل نوع بافتی
> که باید ساخته شود، تنظیم می شوند. در مسائل دسته بندی و جداسازی
> پارامترها برای پردازش تصاویر بافت باید تخمین زده شوند. بافت ها با
> استفاده از این روش توسط کراس[^76] و جین سنتز شدند. پارامترهای مدل برای
> مجموعه ای از بافت های طبیعی نیز تخمین زده شدند. پارامترهای تخمینی برای
> ساخت بافت های ترکیبی تخمین زده شدند و نتایج با تصاویر اصلی مقایسه
> شدند. مدل ها، ریزبافت ها را به خوبی تخمین زدند اما برای بافت های منظم
> و غیرهمگون ناموفق بودند.

6.  []{#_Toc334914808 .anchor}فراکتال ها

> بسیاری از سطوح طبیعی دارای ویژگی های کیفی آماری سختی و خود همسانی[^77]
> در ابعاد مختلف هستند. فراکتال ها بسیار مفیدند و در مدل سازی این ویژگی
> ها در پردازش تصاویر کاربرد فراوان دارند. ماندلبورت[^78] هندسه فراکتالی
> را معرفی کرد و اولین کسی بود که به وجود فراکتال ها در جهان واقعی اشاره
> کرد.
>
> ما ابتدا یک فراکتال معین را تعریف می کنیم تا بتوانیم بعضی از اصول کلی
> را معرفی کنیم. خودهمسانی در میان ابعاد فراکتال یک موضوع بسیار سخت است.
> یک فراکتال معین با استفاده از مفهوم خودهمسانی در ادامه معرفی می شود.
> برای یک مجموعه محدود $A$ در فضای اقلیدسی $n$ بعدی، مجموعه $A$ یک
> مجموعه خودهمسان است اگر $A$ اجتماع $N$ کپی متمایز از خودش باشد که
> ابعاد هر کدام از آنها با نرخ $r$ کوچکتر می شود. ابعاد فراکتال $D$، طبق
> رابطه زیر به عدد $N$ و نرخ$r$ مرتبط می شود:

$$D = \frac{\log N}{\log\left( \frac{1}{r} \right)}$$

> بعد فراکتال معیاری از خشونت سطح را به دست می دهد. هر چه ابعاد فراکتال
> بزرگتر باشد، بافت خشن تری خواهیم داشت. پنتلند[^79] این نظریه را مطرح
> کرد که تصاویر بیشتر سطوح طبیعی می توانند به صورت فراکتال های همگرا در
> فضا مدل شوند. بیشتر سطوح طبیعی و به طور خاص سطوح بافتی آن طور که در
> بالا گفته شد، معین نیستند و دارای تغییرات آماری هستند. این امر محاسبه
> ابعاد فراکتال را دشوار می سازد.
>
> روش هایی برای تخمین ابعاد فراکتال $D$ ارائه شده است. یک روش، تخمین
> ابعاد مستطیل بدین شرح است: برای مجموعه محدود $A$ در فضای $n$ بعدی
> اقلیدسی مستطیل هایی با اندازه $L_{\max}$ بر سمتی که مجموعه $A$ را پوشش
> دهد در نظر بگیرید. نسخه با ابعاد تقلیل یافته از $A$ با نرخ $r$ در
> $N = \frac{1}{r^{D}}$ مجموعه مشابه حاصل می شود. این مجموعه جدید می
> تواند با مستطیل هایی با اندازه $L = rL_{\max}$ پوشش داده شود. تعداد
> این مستطیل ها با رابطه زیر به ابعاد فراکتال وابسته می شود:

$$N\left( L \right) = \frac{1}{r^{D}} = \left\lbrack \frac{L_{\max}}{L} \right\rbrack^{D}$$

> سپس ابعاد فراکتال با استفاده از رابطه فوق با این روال تخمین زده می
> شود: برای هر $L$ داده شده، فضای $n$ بعدی را به شبکه ای از مستطیل های
> با اندازه $L$ تقسیم کنید و تعداد مستطیل های پوشش دهنده $A$ را شمارش
> کنید. این رویه را برای مقادیر مختلف $L$ تکرار کنید. سپس مقدار بعد
> فراکتال$D$ را از شیب خط تخمین بزنید:

$$\ln\left( N\left( L \right) \right) = \  - D\ln\left( L \right) + Dln(L_{\max})$$

> این امر با محاسبه درون یابی و تقریب کمترین مربعات بر روی داده ها امکان
> پذیر است.
>
> یک روش توسعه یافته در تخمین ابعاد فراکتال توسط وُس[^80] پیشنهاد داده
> شد. فرض کنید می خواهیم ابعاد فراکتال را برای یک تصویر بر سطح $A$ تخمین
> بزنیم. فرض کنید $p(m,L)$ نشان دهنده احتمال وجود $m$ نقطه درون یک
> مستطیل با طول $L$ است که بر روی یک نقطه اختیاری از سطح $A$ مرکزیت
> یافته است. زمانی که تصویر را با مستطیل هایی با طول $L$ پوشش می دهیم،
> آنگاه $\left( \frac{M}{m} \right)P(m,l)$ تعداد مستطیل های مورد انتظار
> برای در بر داشتن $m$ نقطه در درون خود خواهد بود. تعداد مستطیل های مورد
> انتظار برای پوشش کل تصویر از رابطه زیر قابل محاسبه است:

$$E\left\lbrack N\left( L \right) \right\rbrack = M\sum_{m = 1}^{N}{\left( \frac{1}{m} \right)P(m,l)}$$

> مقدار مورد انتظار برای $N(L)$ متناسب با $L^{- D}$ است و به همین دلیل
> می تواند در تخمین ابعاد فراکتال $D$ مورد استفاده قرار گیرد. همچنین روش
> های دیگری در تخمین ابعاد فراکتال پیشنهاد شده است. به عنوان مثال
> سوپر[^81] و بوویک[^82] فیلترهای گاوسی و روش های پردازش سیگنال را در
> تخمین ابعاد فراکتال برای تصاویر بافتی مورد استفاده قرار دادند.
>
> ابعاد فراکتال برای استخراج همه ویژگی های بافت کافی نیست. تجربه نشان
> داده که ممکن است بافت های متعدد و متفاوتی با ابعاد فراکتالی یکسان
> موجود باشند. بنابراین، معیار دیگر که از آن به حفرگی[^83] یاد می شود،
> به منظور دریافت ویژگی های بافت پیشنهاد داده شده است که ما را قادر می
> سازد این بافت ها را از یکدیگر تشخیص دهیم. حفرگی به صورت زیر تعریف می
> شود:

$$Ʌ = E\left\lbrack \left( \frac{M}{E(M)} - 1 \right)^{2} \right\rbrack$$

> که در آن $M$ جمع مجموعه فراکتال ها و $E(M)$ مقدار مورد انتظار برای $M$
> است. این معیار اختلاف بین جمع واقعی و جمع مورد انتظار را اندازه گیری
> می نماید. زمانی که بافت نرم است معیار حفرگی کوچک است و زمانی که بافت
> زبر است، این معیار مقدار بزرگ دارد. جمع یک مجموعه فراکتال با استفاده
> از قانون توان با $L$ (طول مستطیل ها) مرتبط می شود:

$$M\left( L \right) = KL^{D}$$

> وُس برای محاسبه معیار حفرگی استفاده از توزیع احتمال را به شکل زیر
> پیشنهاد داد:

$$Ʌ\left( L \right) = \frac{M^{2}\left( L \right) - {(M\left( L \right))}^{2}}{{(M(L))}^{2}}$$

> که در آن:

$$M\left( L \right) = \sum_{m = 1}^{N}{\text{mP}\left( \text{m.L} \right)\text{\ \ \ \ \ \ \ \ \ \ \ \ }M^{2}\left( L \right) = \sum_{m = 1}^{N}{m^{2}P(m,L)}}$$

> $E(M(L))$ مقدار مورد انتظار برای $M(L)$ است. این معیار از تصویر سپس به
> عنوان یکی از ویژگی های بافت در کاربردهای دسته بندی و جداسازی قابل
> استفاده است.

اهانین[^84] و دابز[^85] کارایی ویژگی های بافتی مختلف را مورد بررسی قرار
دادند. آنها ویژگی های بافتی را با این محدودیت مطالعه کردند :«کدام ویژگی
نرخ دسته بندی را به بهترین شکل بهینه می کند؟» آنها چهار ویژگی فراکتالی،
شانزده ویژگی مربوط به ماتریس تکرار، چهار ویژگی مربوط به فیلد تصادفی
مارکوف و گابور را با هم مقایسه کردند. ارزیابی بر روی چهار دسته از تصاویر
صورت گرفت: تصاویر فیلد تصادفی گاوس- مارکوف، تصاویر فراکتالی، تصاویر چرم
و صفحه های نقاشی شده. ویژگی های مربوط به ماتریس تکرار عمدتاً نسبت به
سایر ویژگی ها کارایی بهتری داشته است(دقت 88% در دسته بندی) و بعد از آن
ویژگی های فراکتالی دقت خوبی داشته اند (دقت 84% در دسته بندی). استفاده
توأم از این دو دسته ویژگی، دقت دسته بندی را به 91% رساند.

13. []{#_Toc335208999 .anchor}روش های پردازش سیگنال

> تحقیقات فیزیک روان نشان داده است که مغز انسان یک تحلیل فرکانس را بر
> روی تصاویر انجام می دهد. بافت نیز با توجه به ویژگی های خاص خود برای
> این نوع تحلیل مناسب است. در این بخش روشهای مختلف تحلیل بافت بر اساس
> تکنیک های مختلف پردازش سیگنال معرفی می شود. بیشتر این روش ها برای
> محاسبه ویژگی های قابل اتکاء از تصاویر فیلتر شده که در گام های بعدی
> برای دسته بندی و یا جداسازی استفاده می شود، تلاش می کنند.

7.  []{#_Toc334914810 .anchor}فیلترهای دامنه فضایی[^86]

> فیلترهای دامنه فضایی مستقیم ترین راه برای استخراج ویژگی های بافت یک
> تصویر به شمار می آیند. تلاش های اخیر برای تعریف این روش ها بر اندازه
> گیری ظرفیت یال در ناحیه متمرکز شده اند. بافت های نرم تمایل به داشتن
> ظرفیت یال بیشتری نسبت به بافت های زبر در واحد ناحیه هستند. اندازه گیری
> یالی معمولاً با ماسک های ساده یالی مثل عملگر رابرت یا عملگر لاپلاس
> صورت می گیرد. دو ماسک متعامد برای عملگر رابرت و یک عملگر رقمی لاپلاس
> در زیر آورده شده است:

$${رابرت\ عملگرهای\text{\ \ }M}_{1} = \begin{bmatrix}
0 & 1 \\
 - 1 & 0 \\
\end{bmatrix}\text{\ \ \ \ \ \ \ \ \ \ \ \ }M_{2} = \begin{bmatrix}
1 & 0 \\
0 & - 1 \\
\end{bmatrix}\ $$

$$لاپلاس\ عملگر\ L = \begin{bmatrix}
 - 1 & - 1 & - 1 \\
 - 1 & 8 & - 1 \\
 - 1 & - 1 & - 1 \\
\end{bmatrix}$$

> با محاسبه مقدار حاصل از نتایج ماسک رابرت و یا نتایج ماسک لاپلاس، معیار
> یالی بر روی یک ناحیه تصویری قابل محاسبه است.
>
> مالیک[^87] و پرونا[^88] فیلتر مخصوصی را برای مدل کردن درک بافت در
> سیستم شهودی انسان معرفی کردند. مدل پیشنهادی آنها شامل سه گام می شود:1-
> پیچش تصویر توسط مجموعه ای از فیلترهای زوج متقارن و تصحیح نیم موج. 2-
> بازداری از پاسخ های نادرست در یک ناحیه محلی. 3- تشخیص مرز بین بافت های
> مختلف. فیلتر زوج متقارن مورد استفاده آنها شامل توابع آفست گاوسی متنوع
> می باشد. تصحیح نیم موج و منع خطا روش هایی برای معرفی غیر خطی بودن
> ویژگی های بافتی هستند. غیرخطی بودن برای تمییز جفت بافت های با میانگین
> روشنی و آماره های دسته دوم مشابه، مورد نیاز است. کشف مرزهای بافت با یک
> روش تشخیص یال مستقیم از ویژگی های تصویر که از مرحله دوم به دست آمده
> است، صورت می گیرد. این روش بر روی نمونه بافت های مختلفی عمل می کند و
> می تواند بین بافت های طبیعی و بافت های ترکیبی (مصنوعی) تمایز قائل شود.
>
> مجموعه دیگری از فیلترهای فضایی بر پایه گشتاور های فضایی بنا نهاده شده
> اند. گشتاور $(p + q)$ُم بر روی یک ناحیه از تصویر$R$ با استفاده از
> رابطه زیر به دست می آید:

$$m_{\text{pq}} = \sum_{(x,y) \in R}^{}{x^{p}y^{q}I(x,y)}$$

اگر ناحیه $R$ یک ناحیه مستطیل شکل محلی باشد و گشتاور به ازای تمام پیکسل
های درون این ناحیه محاسبه شود، این کار معادل با فیلتر کردن تصویر با ماسک
های فضایی است. سپس تصاویر فیلتر شده متناظر با گشتاورها، به عنوان ویژگی
های بافت مورد استفاده قرار می گیرند. ماسک ها با تعریف یک پنجره با ابعاد
$w \times w$ و یک دستگاه مختصات محلی که مرکز آن در این پنجره است، به دست
می آیند. فرض کنیم $(i,j)$ مختصات تصویر است که گشتاورها در آن محاسبه می
شوند. برای مختصات پیکسل های $(m,n)$ که درون پنجره $w \times w$ مرکزیت
یافته در $(i,j)$ می افتند، مختصات نرمال شده $(x_{m},\ y_{n})\ $ به شکل
زیر به دست می آید:

$$x_{m} = \frac{(m - i)}{(\frac{w}{2})}\text{\ \ \ \ \ \ \ \ \ \ \ }y_{n} = \frac{(n - j)}{(\frac{w}{2})}$$

سپس گشتاورهای درون یک پنجره مرکزیت یافته در $(i,j)$ از طریق حاصل جمع زیر
قابل محاسبه است:

$$m_{\text{pq}} = \sum_{n = - w/2}^{w/2}{\sum_{m = - w/2}^{w/2}{I(m,n)x_{m}^{p}y_{n}^{q}}}$$

ضریب هر پیکسل درون پنجره برای محاسبه حاصل جمع همان چیزی است که ضرایب
ماسک را تعریف می کند. اگر $R$ یک ناحیه 3$\times$3 باشد، ماسک های حاصل به
شکل زیر خواهد بود:

$$M_{00} = \begin{bmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1 \\
\end{bmatrix}\text{\ \ \ \ \ }M_{10} = \begin{bmatrix}
 - 1 & - 1 & - 1 \\
0 & 0 & 0 \\
1 & 1 & 1 \\
\end{bmatrix}\text{\ \ \ \ \ \ \ \ \ }M_{01} = \begin{bmatrix}
 - 1 & 0 & 1 \\
 - 1 & 0 & 1 \\
 - 1 & 0 & 1 \\
\end{bmatrix}$$

$$M_{20} = \begin{bmatrix}
1 & 1 & 1 \\
0 & 0 & 0 \\
1 & 1 & 1 \\
\end{bmatrix}\text{\ \ \ \ \ \ \ \ }M_{11} = \begin{bmatrix}
1 & 0 & - 1 \\
0 & 0 & 0 \\
 - 1 & 0 & 1 \\
\end{bmatrix}\text{\ \ \ \ \ \ \ \ \ \ \ \ }M_{02} = \begin{bmatrix}
1 & 0 & 1 \\
1 & 0 & 1 \\
1 & 0 & 1 \\
\end{bmatrix}$$

ویژگی های مبتنی بر گشتاور استفاده موفقیت آمیزی در جداسازی بافت داشته
اند. مثالی از دو نوع بافت در یک تصویر و جداسازی بافت ها را در شکل زیر
مشاهده می کنید:

![](media/image14.png){width="5.295511811023622in"
height="1.6146784776902887in"}

11. []{#_Toc335208198 .anchor}نتایج جداسازی با استفاده از ویژگی های
    بافتی مبتنی بر گشتاور

<!-- -->

8.  []{#_Toc334914811 .anchor}فیلتر دامنه فوریه

بهترین تحلیل فرکانس تصاویر بافتی ، توسط دامنه فوریه انجام شده است. بنابر
نتایج فیزیک روان، سیستم بینایی انسان، تصاویر بافتی را به بخش های فرکانسی
و جهتی خود تجزیه می کند. کانال های چندگانه که منجر به فرکانس های مختلف
می شوند نیز تحت عنوان پردازش چند رزولوشنی در این حوزه کاربرد دارد. مفهوم
پردازش چند رزولوشنی بیشتر در مدل های موجک مورد توسعه و کاربرد قرار گرفته
است. بر اساس نتایج این تحقیقات سیستم تحلیل بافت برای توسعه خود، دست به
دامان فیلترهای در دامنه فوریه شده است تا بتواند ویژگی های تصویر را به
دست بیاورد. ایده اصلی، همانند ویژگی های محاسبه شده از حلقه ها و خط هاست
که در بخش های قبلی معرفی شد با این تفاوت که اطلاعات فاز نگه داری می شود.
کوجینز و جین مجموعه ای از فیلترهای انتخابی فرکانس ها و جهت ها را در
رویکرد فیلتر چندکاناله به کار بردند. هر فیلتر یا انتخاب کننده فرکانس است
و یا انتخاب کننده جهت. چهار فیلتر جهتی داریم که با زوایای 0 و 45 و 90 و
135 درجه مرکزیت یافته اند. تعداد فیلترهای فرکانسی بستگی به اندازه تصویر
دارد. برای یک تصویر با اندازه 128\*128 شش فیلتر فرکانسی مرکزیت یافته در
1و2و4و8و16و32و64 حلقه بر تصویر استفاده می شود. این فیلترها قدرت دسته
بندی و جداسازی تصاویر متعدد طبیعی را دارند.

4.  []{#_Toc335209002 .anchor}یادگیری و دسته بندی بافت تصاویر

    14. []{#_Toc335209003 .anchor}مقدمات دسته بندی

> دسته بندی به عملیات تخصیص اشیاء به یکی از دسته های از پیش تعریف شده
> گفته می شود. دسته بندی یک مسأله فراگیر است که کاربردهای گوناگونی را
> دربر می گیرد. تشخیص هرزنامه ها بر اساس سرایند و محتوای ایمیل های
> دریافتی، دسته بندی سلول های بدخیم یا خوش خیم بر اساس نتایج اسکن های
> MRI و دسته بندی کهکشان ها بر اساس شکلشان، نمونه هایی از کاربردهای دسته
> بندی هستند.
>
> در این بخش اصول کلی دسته بندی را معرفی می کنیم و سپس به توصیف دقیق تر
> روش های دسته بندی مورد استفاده در این پروژه خواهیم پرداخت.
>
> داده های ورودی برای عملیات دسته بندی مجموعه ای از رکوردها هستند که به
> عنوان یک نمونه ورودی شناخته می شوند و با $(x,y)\ $ نمایش داده می شوند
> که در آن $x$ مجموعه ویژگی ها و $y$ یک ویژگی خاص است که به عنوان برچسب
> دسته درنظر گرفته شده است. مجموعه ویژگی ها می توانند داده های گسسته و
> یا پیوسته باشند. اگر داده ها پیوسته هم باشند باید برچسب دسته گسسته
> باشد. این ویژگی، تفاوت بین دسته بندی و رگرسیون را آشکار می سازد.
>
> **تعریف:** دسته بندی، به عملیات یادگیری تابع $f$ گفته می شود که هر
> مجموعه ویژگی $x$ را به یکی از دسته های از پیش تعریف شده $y$ نگاشت می
> دهد. به این تابع، مدل دسته بندی نیز اطلاق می شود. مدل های دسته بندی
> شامل مدل های توصیفی و مدل های پیشگویانه می باشند.

-   مدل توصیفی[^89]

> یک مدل دسته بندی می تواند به عنوان یک ابزار توضیحی برای تشخیص اشیاء از
> دسته های مختلف به کار رود. به عنوان مثال، برای یک زیست شناس، مدلی
> توصیفی که بتواند اطلاعات یک مجموعه داده ای را در قالب گزاره های کلی
> برای توصیف جانداران مختلف انتزاع بخشد، بسیار مفید خواهد بود.

-   مدل پیشگویانه[^90]

> یک مدل دسته بندی می تواند برای تخمین برچسب دسته یک رکورد شناخته نشده
> به کار رود. مطابق شکل زیر یک مدل دسته بندی را می توان به صورت جعبه
> سیاهی درنظر گرفت که به طور خودکار یک برچسب دسته را با دریافت مجموعه
> ویژگی های یک رکورد ناشناخته، تخصیص می دهد.

![](media/image15.png){width="5.406045494313211in"
height="1.3669728783902013in"}

12. []{#_Toc335208200 .anchor}مدل پیشگویانه به صورت یک جعبه سیاه. با
    دریافت مجموعه ویژگی های یک نمونه ناشناخته برچسب دسته آن را تعیین می
    کند

> روش های دسته بندی اکثراً برای تقریب یا توصیف مجموعه داده های دودویی یا
> توصیفی مناسبند و معمولاً برای داده های ترتیبی کاربردی ندارند؛ (به
> عنوان مثال دسته بندی افراد به گروه های پیر، جوان و کودک) زیرا این روش
> ها ترتیب ضمنی بین دسته ها را نادیده می گیرند. انواع دیگر روابط بین
> دسته ها مثل پدر و فرزندی (ارث بری) نیز توسط این روش ها نادیده گرفته می
> شود. در ادامه به رویکرد های کلی حل مسائل دسته بندی خواهیم پرداخت.
>
> **رویکردهای کلی برای حل مسائل دسته بندی**
>
> یک روش دسته بندی، رویکردی سیستماتیک برای ساخت مدل های دسته بندی از
> مجموعه های داده ای است. از جمله این روش ها می توان به درخت تصمیم، دسته
> بندهای مبتنی بر نقش، شبکه های عصبی، ماشین های اتکای برداری (SVM) و
> دسته بندهای بیزی اشاره کرد. هر کدام از این روش ها دارای یک الگوریتم
> یادگیری برای توصیف مدلی است که به بهترین وجه ممکن، مجموعه ویژگی ها را
> به دسته ها نگاشت دهد. مدلی که توسط الگوریتم یادگیری ساخته می شود باید
> داده های ورودی را به خوبی تطبیق دهد و برچسب دسته رکورد هایی را که تا
> کنون ندیده است، به درستی تخمین بزند. بنابراین یک هدف کلیدی الگوریتم
> های یادگیری ساختن مدل هایی با قابلیت انتزاع خوب است. شکل زیر یک رویکرد
> کلی را برای حل مسائل دسته بندی نشان می دهد.

![C:\\Users\\M\\Desktop\\ml.jpg](media/image16.jpeg){width="5.645893482064742in"
height="4.559632545931758in"}

13. []{#_Toc335208202 .anchor}رویکرد کلی در حل مسائل دسته بندی

> در ابتدا یک مجموعه آموزش که شامل رکوردهایی با برچسب کلاس معین است باید
> فراهم شود. مجموعه آموزش برای ساختن یک مدل دسته بندی به کار می رود. این
> مدل سپس به مجموعه آزمون اعمال می شود که شامل رکوردهایی با برچسب نامعین
> است.
>
> ارزیابی کارایی یک مدل دسته بندی بر اساس تعداد رکوردهای آزمون که توسط
> مدل به صورت درست یا غلط تخمین زده شده اند، صورت می گیرد. این اعداد در
> جدولی به نام ماتریس تداخل قرار می گیرند. شکل زیر ماتریس تداخل را برای
> یک مسأله دسته بندی دودویی نشان می دهد:

![](media/image17.png){width="4.776170166229221in"
height="1.6055041557305336in"}

هر درایه $F_{\text{ij}}$ در این ماتریس تعداد رکوردهای از دسته $i$ است که
تخمین زده شده متعلق به دسته $j$ است. به عنوان مثال، $F_{01}$ تعداد
رکوردهای دسته 0 است که به غلط به دسته 1 تخمین زده شده است. بر اساس درایه
های ماتریس تداخل، تعداد کل تخمین های صحیح به دست آمده از مدل برابر با
$(F_{11} + F_{00})$ است و تعداد کل تخمین های غلط $(F_{10} + F_{01})$
است.

اگرچه ماتریس تداخل، اطلاعاتی را که برای محاسبه کارایی مدل دسته بندی
موردنیاز است فراهم می آورد، اما خلاصه سازی این اطلاعات به صورت یک عدد
منفرد، مقایسه مدل را با سایر مدل ها آسانتر می سازد. این امر می تواند به
وسیله یک معیار کارایی مانند **دقت**[^91] که به صورت زیر محاسبه می شود،
صورت گیرد:

$$دقت = \ \frac{درست\ های\ تخمین\ تعداد}{ها\ تخمین\ کل\ تعداد} = \frac{f_{11} + f_{00}}{f_{11} + f_{00} + f_{01} + f_{00}}$$

*از دیگر سو، کارایی یک مدل می تواند توسط نرخ خطایش تعیین شود که از طریق
رابطه زیر به دست می آید:*

$$خطا\ نرخ = \ \frac{غلط\ های\ تخمین\ تعداد}{ها\ تخمین\ کل\ تعداد} = \frac{f_{10} + f_{01}}{f_{11} + f_{00} + f_{01} + f_{00}}$$

*بیشتر الگوریتم های دسته بندی، مدل خود را به گونه ای تنظیم می کنند که
بیشترین دقت و یا کمتری نرخ خطا را داشته باشد.*

*در ادامه به معرفی دو روش مشهور در دسته بندی می پردازیم که در این پروژه
مورد استفاده قرار گرفته اند:*

15. []{#_Toc335209004 .anchor}دسته بندی به روش درخت تصمیم

-   یک درخت تصمیم چگونه کار می کند؟

*برای توضیح روش دسته بندی با استفاده از درخت تصمیم، یک مسأله دسته بندی
ساده را در نظر بگیرید: دسته بندی جانوران به دو گروه پستانداران و
غیرپستانداران. فرض کنید یک جانور جدید توسط یک دانشمند شناخته می شود.
چگونه می توانیم این جانور را در یکی از این دو دسته جای دهیم؟ یک راه،
مطرح کردن مجموعه سوال هایی از ویژگی های این جانور است. اولین سوالی که
ممکن است مطرح کنیم این است که این جانور خونسرد است یا خونگرم؟ اگر خونسرد
باشد، پستاندار نیست. در غیر اینصورت، پرنده و یا پستاندار است. اگر پرنده
باشد، در مورد نر و یا ماده بودن آن سوال می کنیم. اگر ماده باشد، پستاندار
است و اگر نر باشد پستاندار نیست(به استثنای پرندگان تخم گذار)*

*مثال فوق نشان می دهد که چگونه می توانیم یک مساله دسته بندی را با طرح
مجموعه سوال هایی درباره ویژگی های رکورد داده ای جدید، حل کنیم. هر گاه
پاسخی دریافت کردیم، فرایند پرسش را تا جایی پیش می بریم که به یک نتیجه
گیری درباره دسته رکورد داده ای جدید برسیم. این مجموعه سوال ها و پاسخ های
ممکن به آنها می تواند در قالب یک درخت تصمیم سازماندهی شود. درخت تصمیم یک
ساختار سلسله مراتبی است که شامل گره هایی با یال های متصل به گره هاست.
شکل زیر درخت تصمیم را برای مساله دسته بندی جانوران به دو دسته پستاندار و
غیرپستاندار نشان می دهد:*

![](media/image18.png){width="4.57542760279965in"
height="2.9082567804024495in"}

14. []{#_Toc335208204 .anchor}کاربرد درخت تصمیم برای تعیین دسته یک
    جاندار شناخته نشده.

*درخت تصمیم دارای سه نوع گره می باشد:*

1.  *گره ریشه: گره ای که هیچ یال ورودی ندارد.*

2.  *گره های داخلی : این گره ها دارای دقیقاً یک یال ورودی و حداقل یک یال
    خروجی هستند.*

3.  *برگ ها: هر کدام از این گره ها دارای دقیقاً یک یال ورودی هستند و یال
    خروجی ندارند.*

*در درخت تصمیم هر برگ دارای یک برچسب دسته است. گره های غیر برگ شامل
شرایطی برای مجموعه ویژگی ها هستند که برای جداسازی رکوردهای با ویژگی های
متفاوت به کار می روند.به عنوان مثال گره ریشه در درخت فوق از ویژگی* دمای
بدن *برای جداکردن جانوران خونگرم از جانوران خونسرد استفاده می کند. از
آنجا که تمام جانوران خونسرد غیر پستاندار هستند، یک برگ با برچسب
غیرپستاندار به عنوان فرزند سمت راست گره ریشه ساخته می شود. اگر جانور
خونگرم باشد، یک ویژگی دیگر به نام* پرنده بودن *برای تشخیص پستاندار بودن
جانور به کار می رود.*

*بعد از تشکیل درخت تصمیم، دسته بندی یک رکورد آزمون بسیار ساده است. با
شروع از ریشه، شرط موجود در گره ها را بر روی رکورد آزمون اعمال می کنیم و
شاخه مناسب را بر اساس خروجی هر گره موجود در مسیر دنبال می کنیم تا به گره
برگ برسیم. با رسیدن به گره برگ، برچسب دسته رکورد آزمون تعیین می شود.*

-   چگونه یک درخت تصمیم بسازیم؟

*به طور کلی، درختان تصمیم بی شماری را می توان از هر مجموعه ویژگی داده
شده تشکیل داد. با توجه به اینکه بعضی از این درختان نسبت به سایر بهینه تر
هستند، یافتن درخت تصمیم کاملاً بهینه به دلیل نمایی بودن فضای جستجو، به
طور نظری امکان پذیر نیست. با این حال الگوریتم تقریباً دقیقی وجود دارد که
در بازه زمانی قابل قبولی درخت تصمیم بهینه را بر اساس مجموعه ویژگی های
داده شده تشکیل می دهد. این الگوریتم عمدتاً از یک راهبرد حریصانه، درخت
تصمیم بهینه را با دنباله ای از تصمیمات بهینه محلی تشکیل می دهد که ویژگی
متناظر با هر یک از این تصمیمات محلی، برای جداسازی داده ها از یکدیگر،
استفاده می شود. یکی از این الگوریتم ها، الگوریتم هانت* [^92]*است که
مبنای بسیاری از الگوریتم های القای درختان تصمیم است . در این بخش به
توضیح الگوریتم هانت و توصیف بخشی از ویژگی های آن می پردازیم.*

-   الگوریتم هانت

*در الگوریتم هانت، یک درخت تصمیم طی یک روند بازگشتی با جداسازی رکوردهای
آموزش به مجموعه هایی که به طور پی در پی خالص تر می شوند، رشد می کند. فرض
کنیم* $D_{t}$ *مجموعه رکوردهای آموزش است که به گره* $t$ *تخصیص داده شده
اند و* $y = \{ y_{1},\ y_{2},\ \ldots,\ y_{c}\}$ *برچسب های دسته ها
باشند. مراحل زیر توصیفی از الگوریتم هانت است:*

***گام اول:** اگر همه رکوردهای موجود در* $D_{t}$ *متعلق به کلاس مشابه*
$y_{t}$ *باشد، آنگاه* $t$ *یک برگ است با برچسب*$y_{t}$ *.*

***گام دوم:** اگر* $D_{t}$ *شامل رکوردهایی باشد که به بیش از یک کلاس
تعلق دارند، یک* شرط آزمون ویژگی *برای جداسازی رکوردها به زیرمجموعه های
کوچکتر انتخاب می شود. برای هر کدام از خروجی های شرط آزمون یک گره فرزند
ساخته می شود و رکوردهای موجود در* $D_{t}$ *بر اساس خروجی ها بین فرزندان
توزیع می شوند. سپس الگوریتم به شکل بازگشتی به هرکدام از گره های فرزند
اعمال می شود.*

16. []{#_Toc335209005 .anchor}دسته بندی به روش ماشین بردار پشتیبان

*یکی از روش های دسته بندی که توجه قابل ملاحظه را به خود جلب کرده است،
ماشین بردار پشتیبان است. این روش ریشه در نظریه یادگیری آماری دارد و
نتایج تجربی امیدبخشی را در بسیاری از کاربردهای عملی مثل تشخیص رقم های
دست نویس و دسته بندی متون نشان داده است. همچنین* SVM *با داده های با
ابعاد بزرگ خیلی خوب کار می کند و از معایب ابعاد بزرگ در داده ها در امان
است. یکی دیگر از جنبه های منحصر به فرد این روش این است که مرزهای تصمیم
را با استفاده از زیرمجموعه هایی از نمونه های آموزش که* بردارهای پشتیبان
*نامیده می شوند، تعیین می کند.*

*برای توضیح ایده اصلی* SVM *ابتدا به معرفی مفهوم* ابرصفحه با حاشیه
ماکزیمال[^93] *می پردازیم و اساس انتخاب چنین ابرصفحه ای را شرح خواهیم
داد. سپس توضیح می دهیم که یک* SVM *خطی برای جستجوی صریح این گونه از
ابرصفحه ها در داده های جدایی پذیر خطی، چگونه قابل آموزش است. *

-   ابرصفحه های با حاشیه بیشینه

*شکل زیر نموداری از یک مجموعه داده ای را نشان می دهد که شامل نمونه هایی
متعلق به دو کلاس مربع ها و دایره هاست. مجموعه داده ای نیز جدایی پذیر خطی
است. ما می توانیم یک ابرصفحه پیدا کنیم که همه مربع ها در یک سمت آن و همه
دایره ها در سمت دیگر آن قرار گیرند. *

![](media/image19.png){width="2.0416666666666665in"
height="1.603883420822397in"}

15. []{#_Toc335208206 .anchor}ابر صفحه های بی شمار برای جدا کردن نمونه
    ها به دو کلاس مختلف

*همان طور که در شکل فوق مشاهده می کنید، به تعداد بی شماری ابرصفحه می
توان برای جدا کردن این دو دسته یافت. اگر چه خطای یادگیری همه آنها صفر
است اما هیچ تضمینی برای اینکه این ابرصفحه ها بتوانند برای نمونه های جدید
نیز به خوبی جداسازی را انجام دهند، وجود ندارد. دسته بند باید یکی از این
ابر صفحه ها را بر اساس اینکه به چه میزان بر روی نمونه های آزمون خوب عمل
می کنند، برای تعیین مرز تصمیم خود، انتخاب کند. *

*برای ملموس تر شدن انتخاب های گوناگون ابرصفحه ها بر خطاهای انتزاع، دو
مرز تصمیم* $B_{1}$ $B_{2}و$ *که در شکل زیر نشان داده شده است را درنظر
بگیرید:*

![](media/image20.png){width="3.660416666666667in" height="3.29375in"}

16. []{#_Toc335208208 .anchor}مقایسه حاشیه های دوابرصفحه جداکننده

*هر دو مرز تصمیم می توانند نمونه های آموزش را بدون خطای دسته بندی*[^94]
*به کلاس های مناسب جدا کنند. هر مرز تصمیم* $B_{i}$ *به یک جفت از ابرصفحه
ها تخصیص می یابد که به ترتیب با* $b_{i1}$ *و* $b_{i2}$ *نمایش داده می
شوند.* $b_{i1}$ *با انتقال یک ابرصفحه موازی از مرز تصمیم تا جایی که به
نزدیکترین مربع مماس شود، انتقال می یابد.* $b_{i2}$ *با حرکت ابرصفحه
تاجایی که به نزدیکترین دایره مماس شود، انتقال می یابد. فاصله بین این دو
ابرصفحه به عنوان حاشیه دسته بند شناخته می شود. همان طور که در شکل فوق
مشاهده می کنید، حاشیه* $B_{1}$ *به شکل قابل توجهی از* $B_{2}$ *بزرگتر
است. در این مثال* $B_{1}$ *به سمت ابرصفحه با بیشترین حاشیه برای نمونه
های آموزش پیش می رود. *

-   اصل بیشترین حاشیه

*مرزهای تصمیم با حاشیه های بزرگ تمایل به تعمیم های باخطای کمتر نسبت به
مرزهای با حاشیه کوچک دارند. هر چه حاشیه کوچکتر باشد، کوچکترین اختلال در
مرزهای تصمیم می تواند اثر قابل توجهی بر دسته بندی آن داشته باشد.
بنابراین دسته بندهایی که مرزهای تصمیم با حاشیه های کوچک را ایجاد می
کنند، حساسیت بیشتری به تطبیق مدل دارند و تمایل به عمومیت بخشی ضعیف به
نمونه های دیده نشده از قبل دارند.*

*توضیح مفصل تری از ارتباط حاشیه یک دسته بند خطی با خطای عمومیت بخشی آن
توسط یک اصل آماری در یادگیری تحت عنوان* کمینه سازی ساختاری ریسک[^95]
*بیان می شود*. *این اصل یک کران بالا برای خطای عمومیت بخشی یک دسته بند
برحسب خطای یادگیری*$(R_{e})$*، تعداد نمونه های آموزش*$(N)$ *و پیچیدگی
مدل معرفی می کند. به طور دقیق تر با احتمال* $1 - \eta$ *خطای عمومیت بخشی
یک دسته بند می تواند به طریق زیر محاسبه شود:*

$$R \leq R_{e} + \varphi\left( \frac{h}{N},\frac{log(\eta)}{N} \right)$$

*که در آن* $\varphi$ *یک تابع افزایشی یکنواخت با ظرفیت* $h$ *است.* SRM
*راهی برای بیان خطای عمومیت بخشی به عنوان سازشی بین خطای آموزش و پیچیدگی
مدل به حساب می آید.*

*ظرفیت یک مدل خطی رابطه عکس با حاشیه اش دارد. مدل های با حاشیه کوچکتر
دارای ظرفیت بیشتر هستند زیرا انعطاف پذیری بیشتری دارند و بر خلاف حاشیه
های بزرگ، می توانند با مجموعه های آموزش بسیاری تطبیق پیدا کنند. بر اساس
اصل* SRM *هر چه ظرفیت افزایش پیدا کند، خطای عمومیت بخشی نیز افزایش پیدا
می کند. بنابراین بهتر است به طراحی دسته بندهای خطی بپردازیم که حاشیه های
مرزهای تصمیمشان را بیشینه می کنند تا مطمئن باشیم خطای عمومیت بخشی آنها
کمینه است. یکی از این دسته بندها، دسته بند خطی است که در ادامه به توضیح
آن خواهیم پرداخت.*

-   روش SVM خطی (حالت جدایی پذیر)

*یک* SVM *خطی دسته بندی است که برای ابرصفحه با بزرگترین حاشیه جستجو می
کند، به همین خاطر این روش را روش دسته بند بیشترین حاشیه می نامند. برای
درک اینکه* SVM *چگونه چنین مرزی را یاد می گیرد، با مباحث کلی در مورد
مرزهای تصمیم و حاشیه یک دسته بند خطی توضیح خود را آغاز می کنیم.*

***مرز تصمیم خطی***

*یک مساله دسته بندی دودویی با* $N$ *نمونه یادگیری را درنظر بگیرید. هر
نمونه با یک تاپل* $(x_{i},y_{i})$ *نمایش داده می شود که* $x_{i}$ *مجموعه
ویژگی ها و* $y_{i}$ *برچسب دسته نمونه است که مقداری بین* -1 *و*1 *را به
خود می گیرد. مرز تصمیم یک دسته بند خطی می تواند به شکل زیر نوشته شود:*

$$w.x + b = 0$$

*که در آن* $w$ *و* $b$ *پارامترهای مدل هستند. شکل زیر یک مجموعه آموزش
دوبعدی را نشان می دهد که شامل مستطیل ها و دایره هاست. یک مرز تصمیم که
نمونه های آموزش را به کلاس های متناظرش تقسیم می کند با یک خط مستقیم نشان
داده شده است.*

![](media/image21.png){width="3.5470778652668415in"
height="2.8453729221347333in"}

17. []{#_Toc335208210 .anchor}معادلات مربوط به ابرصفحه جداکننده و حاشیه
    آن.

*هر نمونه ای که در میان مرز تصمیم قرار گرفته باید معادله فوق را ارضاء
کند. به عنوان مثال اگر x~a~ وx~b~ دو نقطه در مرز تصمیم باشند، آنگاه:*

$$\text{w.}x_{a} + b = 0$$

$$\text{w.}x_{b} + b = 0$$

*با تفریق دو معادله فوق به معادله زیر خواهیم رسید:*

$$w.(x_{b} - x_{a}) = 0$$

*که در آن بردار* $x_{b} - x_{a}$ *برداری موازی با مرز تصمیم است و از*
$a$ *تا* $b$ *امتداد دارد. از آنجا که حاصل ضرب نقطه ای صفر است، مطابق
شکل فوق جهت* $w$ *باید بر مرز تصمیم متعامد باشد. برای هر مربع* $x_{s}$
*واقع در بالای مرز تصمیم، می توان نشان داد:*

$$\text{w.}x_{s} + b = k$$

*که در آن* $k > 0$ *. به طور مشابه، برای هر دایره* $x_{c}$ *واقع در زیر
مرز تصمیم، می توانیم نشان دهیم که:*

$$\text{w.}x_{c} + b = k’$$

*که در آن* $k’ < 0\ $ *. اگر همه مستطیل ها را با* $+ 1$ *و همه دایره ها
را با* $- 1$ *برچسب بزنیم، آنگاه می توانیم برچسب دسته* $y$ *را برای هر
نمونه آزمون* $z$ *از روش زیر تخمین بزنیم:*

$$y = \left\{ \begin{matrix}
1\ \ \ \ \ \ \ \ w.z + b > 0 \\
 - 1\ \ \ \ \ \ \ \ w.z + b < 0 \\
\end{matrix} \right.\ $$

***حاشیه یک دسته بند خطی***

*مربع ها و دایره ای را در نظر بگیرید که در نزدیکترین فاصله نسبت به مرز
تصمیم قرار گرفته اند. از آنجا که مربع در بالای مرز تصمیم قرار گرفته است،
باید معادله* $\text{w.}x_{s} + b = k\ $*را برای یک مقدار مثبت* $k$
*ارضاء کند، در حالی که دایره باید معادله*$\ \text{w.}x_{c} + b = k’$ *را
برای یک مقدار منفی* $k’$ *ارضاء کند. می توانیم پارامترهای* $w$ *و* $b$
*در مرز تصمیم را به گونه ای در نظر بگیریم تا دو ابرصفحه موازی* $b_{i1}$
*و* $b_{i2}$ *به صورت زیر قابل تعریف باشند:*

$$b_{i1}:w.x + b = 1,\ \ \ \ \ \ \ \ \ b_{i2}:w.x + b = - 1$$

*حاشیه مرز تصمیم بر اساس فاصله بین دو ابرصفحه داده شده است. برای محاسبه
حاشیه، فرض کنیم* $x_{1}$ *یک نقطه داده ای بر روی* $b_{i1}$ *و* $x_{2}$
*یک نقطه داده ای بر روی* $b_{i2}$ *باشد. با جایگذاری این نقاط در دو
معادله فوق حاشیه* $d$ *می تواند با تفریق معادله دوم از معادله اول به دست
آید:*

$$\text{w.}\left( X_{1} - X_{2} \right) = 2$$

$$\left\| w \right\| \times d = 2$$

$$\therefore d = \frac{2}{\left\| w \right\|}$$

***یادگیری یک مدل* SVM *خطی***

*مرحله آموزش در* SVM *شامل تخمین پارامترهای* $w$ *و*$b$ *برای مرز تصمیم
داده های آموزش می شود. پارامترها باید به گونه ای انتخاب شوند که شرایط
زیر محقق شود:*

$$\text{w.}x_{i} + b \geq 1\ \ \ if\ \ y_{i} = 1$$

$$\text{w.}x_{i} + b \leq - 1\ \ \ if\ \ y_{i} = - 1$$

*این شرایط این نیاز را ارضاء می کنند که همه نمونه های آموزش دسته*
$y = 1$ *باید بر روی و یا بالای ابر صفحه* $w.x + b = 1$ *قرار گیرند و
نمونه های با دسته* $y = - 1$ *باید بر روی و یا زیر ابرصفحه*
$w.x + b = - 1$ *قرار گیرند. دو نامعادله فوق را می توان به شکل زیر
درآورد:*

$$y_{i}\left( \text{w.}x_{i} + b \right) \geq 1,\ \ \ \ i = 1,2,\ldots.,N$$

*هر چند شرایط فوق برای هر دسته بند خطی کاراست اما* SVM *یک نیاز اضافی را
تحمیل می کند و آن بیشینه بودن حاشیه مرز تصمیم است. بیشینه کردن حاشیه،
معادل با کمینه کردن تابع هدف است:*

$$f\left( w \right) = \frac{\left\| w \right\|^{2}}{2}$$

***تعریف:** (*SVM *خطی، حالت جدایی پذیر): مرحله یادگیری در* SVM *می
تواند به صورت مسأله ارضای محدودیت زیر بیان شود:*

$$\min_{w}\frac{\left\| w \right\|^{2}}{2}$$

$$y_{i}\left( \text{w.}x_{i} + b \right) \geq 1,\ \ \ i = 1,2,\ldots,N$$

*از آنجا که تابع هدف درجه دوم است و محدودیت ها با پارامترهای* $w$ *و*
$b$*خطی هستند، این مسأله به مسأله بهینه سازی تحدب موسوم است که با روش
استاندارد ضریب لاگرانژ قابل حل است. در ادامه به اختصار ایده اصلی حل
مسائل بهینه سازی آورده شده است.*

*در ابتدا باید تابع هدف را به شکلی بنویسیم که دربرگیرنده محدودیت های
تحمیلی باشد. تابع هدف جدید به مسأله بهینه سازی لاگرانژ معروف است:*

$$L_{p} = \frac{1}{2}\left\| w \right\|^{2} - \sum_{i = 1}^{N}{\lambda_{i}\left( y_{i}\left( \text{w.}x_{i} + b \right) - 1 \right)}$$

*که در آن پارامتر* $\lambda_{i}$ *ضریب لاگرانژ خوانده می شود. اولین بخش
تابع فوق همانند تابع هدف پیشین است و بخش دوم آن ارضاء کننده محدودیت های
موجود در نامعادلات ذکر شده است.*

*برای کمینه کردن لاگرانژ باید از تابع* $L_{p}$ *بر حسب* $w$ *و* $b$*مشتق
بگیریم و حاصل را برابر با صفر قرار دهیم:*

$$\frac{\partial L_{p}}{\partial w} = 0 \rightarrow w = \sum_{i = 1}^{N}{\lambda_{i}y_{i}x_{i}}$$

$$\frac{\partial L_{p}}{\partial b} = 0 \rightarrow w = \sum_{i = 1}^{N}{\lambda_{i}y_{i}} = 0$$

*از آنجا که ضرایب لاگرانژ نامعلوم هستند، هنوز نمی توانیم* $w$ *و*$b$ *را
به دست آوریم. یک راه برای ارضای نامعادلات تبدیل آنها به مجموعه ای از
معادلات محدودیت است. این امر تا زمانی که ضرایب لاگرانژ غیرمنفی هستند،
امکان پذیر است. این تبدیل ها، محدودیت های زیر را بر ضرایب لاگرانژ تحمیل
می کند که به شرایط* KKT *معروف هستند:*

$$\lambda_{i} \geq 0,$$

$$\lambda_{i}\left\lbrack y_{i}\left( \text{w.}x_{i} + b \right) - 1 \right\rbrack = 0$$

*در نگاه اول ممکن است به نظر برسد که به تعداد نمونه های آموزش، ضریب
لاگرانژ وجود دارد. اما بسیاری از ضرایب لاگرانژ بعد از اعمال محدودیت فوق،
صفر می شوند. محدودیت فوق می گوید باید تا زمانی که نمونه* $x_{i}$
*معادله* $y_{i}(w.x_{i} + b) = 1\ $ *را ارضاء کند، ضریب لاگرانژ*
$\lambda_{i}$ *صفر باشد. چنین نمونه آموزشی با* $\lambda_{i} \geq 0$ *که
بین* $b_{i1}$ *و* $b_{i2}$ *می افتد، یک بردار پشتیبان است. نمونه های
آموزشی که بین این دو ابرصفحه نمی افتند، دارای*$\lambda_{i} = 0$ *هستند.
برای سهولت در حل مساله بهینه سازی معادلات فوق را به فرم لاگرانژ دوگانه
دو می آوریم:*

$$L_{D} = \sum_{i = 1}^{N}{\lambda_{i} - \frac{1}{2}\sum_{i,j}^{}{\lambda_{i}\lambda_{j}y_{i}y_{j}x_{i}x_{j}}}$$

*تفاوت های کلیدی بین لاگرانژ یگانه و لاگرانژ دوگانه عبارتند از:*

1.  *لاگرانژ دوگانه تنها شامل ضرایب لاگرانژ و داده های آموزش است، در
    حالی که لاگرانژ یگانه علاوه بر این ها شامل، پارامترهای مرز تصمیم نیز
    می شود. هر چند که نتیجه هر دو راه حل یکسان است.*

2.  *عبارت دوم در معادله فوق دارای علامت منفی است. این بدین معنی است که
    مساله کمینه سازی اولیه با لاگرانژ یگانه* $L_{p}$ *به مساله بیشینه
    سازی با لاگرانژ دوگانه* $L_{D}$ *تبدیل شده است.*

> *برای مجموعه های داده ای بزرگ، مساله بهینه سازی دوگانه می تواند با
> استفاده از روش های عددی مانند برنامه نویسی درجه دوم حل شود. زمانی که*
> $\lambda_{i}$ *به دست آید، مرز تصمیم می تواند به شکل زیر بیان شود:*

$$\left( \sum_{i = 1}^{N}{\lambda_{i}y_{i}X_{i}X_{j}} \right) + b = 0$$

$b$ *با حل معادله زیر برای بردارهای پشتیبان محاسبه می شود.*

$$\lambda_{i}\left\lbrack y_{i}\left( \text{w.}X_{i} + b \right) - 1 \right\rbrack = 0$$

-   SVM خطی (حالت جدایی ناپذیر)

*شکل زیر مجموعه داده ای مشابه با حالت قبل را نشان می دهد با این تفاوت که
در این مجموعه داده ای دو نمونه* $P$ *و*$Q$ *نیز وجود دارند.*

![](media/image22.png){width="3.7152777777777777in"
height="3.3027777777777776in"}

18. []{#_Toc335208212 .anchor}مقایسه دو ابرصفحه برای جدا کردن نمونه ها

*هر چند که مرز تصمیم* $B_{1}$ *در دسته بندی نمونه های جدید موفق نیست و*
$B_{2}$ *آنها را به خوبی دسته بندی می کند، این بدین معنا نیست که مرز
تصمیم* $B_{2}$ *از* $B_{1}$ *بهتر است، چرا که ممکن است نمونه های جدید در
داده های آموزش نویز به حساب آیند. هنوز باید* $B_{1}$ *را بر*$B_{2}$
*ترجیح دهیم زیرا دارای حاشیه بیشتری هست. در هر صورت، آنچه که در بخش قبل
به عنوان* SVM *معرفی کردیم، فقط قادر به ایجاد نواحی تصمیمی است که داده
های آن بدون خطا هستند. در این بخش با معرفی روش* حاشیه نرم *قادر به تحمل
خطاهای کوچک در نمونه های آموزش خواهیم بود. در این روش باید بین پهنای
حاشیه و تعداد خطاهای داده های آموزش، سازشی پیشه کنیم.*

*شرایط محدود کننده در این روش به شکل زیر در می آید:*

$$\text{w.}x_{i} + b \geq 1 - \xi_{i}\text{\ \ if\ }y_{i} = 1$$

$$\text{w.}x_{i} + b \leq - 1 + \xi_{i}\text{\ \ if\ }y_{i} = - 1$$

*که در آن متغیر ضعف مقداری مثبت دارد. برای تبیین نقش متغیر ضعف شکل فوق
را در نظر بگیرید. دایره* $P$ *یکی از نمونه هایی است که از
معادله*$\ \text{w.}x_{i} + b \leq - 1\ \ ,\ y = - 1$ *تخطی می کند. فرض
کنیم معادله* $w.x + b = - 1 + \xi\ $ *توصیف کننده خطی موازی با مرز تصمیم
باشد که از نقطه* $P$ *می گذرد. می توان نشان داد که فاصله بین این خط و
ابرصفحه* $w.x + b = - 1\ $ *برابر است با*
$\frac{\xi}{\left\| w \right\|}$ . بنابراین $\xi$ *تخمینی از خطای مرز
تصمیم بر روی نمونه آموزش* $P$ *را فراهم می آورد.*

*در حالت کلی می توانیم تابع هدف مشابه حالت قبل را با محدودیت های فوق
برای یافتن مرز تصمیم به کار ببریم. اما از آنجا که هیچ محدودیتی را بر
تعداد اشتباهاتی که مرز تصمیم مرتکب آنها شده است، نداریم الگوریتم یادگیری
ممکن است یک مرز تصمیم با حاشیه بزرگ اما با خطاهای بسیار زیاد را مطابق
شکل زیر به دست دهد:*

![](media/image23.png){width="3.06784886264217in"
height="2.357798556430446in"}

19. []{#_Toc335208214 .anchor}یک مرز تصمیم با حاشیه بزرگ اما خطاهای
    زیاد.

*برای حل این مشکل، تابع هدف باید به گونه ای تغییر یابد که مرزهای تصمیم
با مقادیر بزرگ برای متغیر ضعف را تنبیه نماید. تابع هدف تغییر یافته به
شکل زیر خواهد بود:*

$$f(w) = \frac{\left\| w \right\|^{2}}{2} + C\left( \sum_{i = 1}^{N}\xi_{i} \right)^{k}$$

*که در آن* $C$ *و*$k$ *پارامترهای تعریف شده توسط کاربر هستند و خطاهای
موجود در دسته بندی نمونه های آموزش را تنبیه می کنند. در این بخش برای
سادگی متغیر* $k$ *را برابر با 1 فرض می کنیم. متغیر* $C$ *می تواند بر
اساس کارایی مدل بر روی مجموعه اعتبارسنجی تعیین شود.*

*تابع لاگرانژ برای این مساله بهینه سازی می تواند به شکل زیر نوشته شود:*

$$L_{p} = \frac{1}{2}\left\| w \right\|^{2} + C\sum_{i = 1}^{N}\xi_{i} - \sum_{i = 1}^{N}{\lambda_{i}\left\{ y_{i}\left( \text{w.}X_{i} + b \right) - 1 + \xi_{i} \right\}} - \sum_{i = 1}^{N}{\mu_{i}\xi_{i}}$$

*که در آن دو جمله اول تابع هدف هستند که باید کمینه شوند، جمله سوم
نامعادلات محدودیت را برای متغیرهای ضعف بیان می کند و آخرین جمله حاصل شرط
غیرمنفی بودن مقادیر* $\xi_{i}$ است. با تکرار مراحل محاسبات حالت قبلی
تابع لاگرانژ مرتبه دوم به شکل زیر محاسبه می شود:

$$L_{D} = \sum_{i = 1}^{N}\lambda_{i} - \frac{1}{2}\sum_{i,j}^{}{\lambda_{i}\lambda_{j}y_{i}y_{j}X_{i}X_{j}}$$

که با تابع لاگرانژ به دست آمده برای حالت قبلی (خطی جدایی پذیر) یکسان
است. با این حال، محدودیت هایی که بر $\lambda_{i}$ ها تحمیل می شود، به
طرز قابل توجهی با حالت قبلی متفاوت است. ضرایب لاگرانژ در حالت جدایی
ناپذیر خطی باید شرط $0 \leq \lambda_{i} \leq C$ را ارضاء کنند.

مساله محاسبه ضرایب لاگرانژ دوگانه به صورت عددی با استفاده از برنامه
نویسی درجه دوم قابل حل است.

5.  []{#_Toc335209006 .anchor}نتایج

در این پروژه، در استخراج ویژگی های بافتی تصاویر سنگ از روش آماری ماتریس
تکرار برای محاسبه وابستگی فضایی درجه تیرگی پیکسل ها استفاده کردیم. پس از
تشکیل ماتریس تکرار، چهار ویژگی گشتاور زاویه ای مرتبه دوم [^96]، واریانس
[^97]، گشتاور تفاضل معکوس [^98]و همبستگی[^99] را محاسبه کردیم و ملاک
دسته بندی تصاویر سنگ قرار دادیم. برای دسته بندی تصاویر از دو روش درخت
تصمیم و SVM استفاده کردیم.

در این پروژه نمونه هایی از 4 نوع سنگ متعلق به معادن مختلف مورد بررسی
قرار گرفتند. تعداد نمونه های آموزش در مجموع 108 نمونه و تعداد نمونه های
آزمون 36 نمونه است.

در شکل زیر نمودار پراکندگی ویژگی ها را مشاهده می کنید:

![](media/image24.png){width="3.8878587051618547in"
height="3.4479166666666665in"}

20. []{#_Toc335208216 .anchor}نمودار پراکندگی ویژگی های استخراج شده از
    بافت تصاویر سنگ.

همان طور که می بینید بعضی از این ویژگی ها در تشخیص و تمییز سنگ ها کمک
بسیاری می کنند. هنگامی که از روش درخت تصمیم برای یادگیری الگوی بافت سنگ
ها استفاده کردیم، به دقت 97.22 رسیده ایم. هنگامی که از روش SVM برای
یادگیری الگوهای بافتی استفاده کردیم، دقت 86.11 را تجربه کردیم. زمان
استخراج ویژگی های 144 نمونه 55899 میلی ثانیه، زمان یادگیری و تشکیل مدل
برای روش درخت تصمیم 4 میلی ثانیه و برای روش SVM، 2 میلی ثانیه شد. زمان
آزمون یک نمونه جدید به طور متوسط 380 میلی ثانیه به دست آمد.

با توجه به دقت به دست آمده از درخت تصمیم، از 36 نمونه ای که به عنوان
مجموعه آزمون به مدل داده شد، تنها در یک مورد دچار اشتباه شده است و به
جای اینکه سنگ را در دسته A جای دهد، آن را در دسته D قرار داده است. در
شکل زیر، خطوط افقی مشخص کننده مقدار ویژگی های مربوط به این نمونه هستند:

![](media/image25.png){width="3.8020833333333335in"
height="3.3645833333333335in"}

21. حالت خطا در آزمون روش درخت تصمیم

همان طور که در شکل فوق مشاهده می کنید، ویژگی های واریانس و گشتاور دوم
زاویه ای برای این نمونه نسبت به سایر نمونه های نوع A متفاوت است و از سوی
دیگر تمام ویژگی ها در محدوده ویژگی های سنگ های نوع D قرار گرفته اند.
همین امر، درخت تصمیم را در تشخیص نوع این سنگ دچار خطا کرده است.

با دقت در شکل فوق می توان فهمید ویژگی گشتاور دوم زاویه ای برای جدا کردن
سنگ های نوع B وC از سنگ های نوع A وD مناسب است. همچنین ویژگی گشتاور
معکوس تفاضلی تقریباً در هر چهار نوع سنگ، متفاوت است هر چند برای تمییز
بین سنگ های نوع C وD چندان کارا به نظر نمی رسد. ویژگی همبستگی برای جدا
کردن نوع A از نوع های B وC و نیز از نوع D مناسب است اما برای جدا کردن
سنگ های نوع B وC از یکدیگر چندان مناسب نیست. ویژگی واریانس، کم ارزش ترین
ویژگی در تفکیک نوع سنگ ها بوده و جز تمییز سنگ های نوع A از سایر سنگ ها
نقش چندانی در تفکیک نمونه ها نداشته است.

هنگامی که از روش ماشین بردار پشتیبان برای دسته بندی بافت تصاویر استفاده
کردیم، مدل شکل گرفته، در 5 نمونه از 36 نمونه آزمون دچار خطا شده است. هر
5 خطا در تمییز بین سنگ های نوع A از D بوده است. در 4 مورد، سنگ نوع A در
دسته D جای گرفته و در یک مورد سنگ نوع D در دسته A جای گرفته است. در شکل
زیر، 4 حالتی را که سنگ نوع A در دسته D قرار گرفته است، مشاهده می کنید:

![](media/image26.png){width="4.739583333333333in"
height="4.307139107611548in"}

22. چهار حالت خطای روش ماشین بردار پشتیبان که سنگ های نوع A را در دسته D
    جای می دهد.

در قسمت (الف) ویژگی های واریانس و همبستگی نسبت به سایر نمونه های دسته A
متفاوت است و اتفاقاً با ویژگی های واریانس و همبستگی دسته D تلاقی پیدا
کرده است و به همین علت به عنوان سنگ دسته D شناخته شده است. در قسمت (ب)
نیز اتفاقی مشابه افتاده با این تفاوت که اختلاف ویژگی های نمونه موردنظر
با ویژگی های دسته A چندان زیاد نیست. در قسمت های (پ) و (ت) علاوه بر
ویژگی گشتاور دوم زاویه ای، ویژگی همبستگی نیز از دسته A فاصله گرفته و با
دسته D تلاقی پیدا کرده است.

شکل زیر، حالتی را نشان می دهد که سنگ نوع D از دسته A تشخیص داده شده است:

![](media/image27.png){width="3.8229166666666665in"
height="3.4791666666666665in"}

23. حالت خطای پنجم ماشین بردار پشتیبان که سنگ نوع D را در دسته A جای
    داده است.

واضح است که ویژگی همبستگی، با دسته A تلاقی ضعیف تری نسبت به دسته D دارد
و همین امر سبب خطا در تشخیص شده است.

با نگاهی کلی به تمام حالت های خطای فوق می توان نتیجه گرفت، مدل تنها در
تشخیص سنگ های نوع A وD ممکن است به اشتباه بیفتد و دلیل اصلی آن پراکندگی
ویژگی گشتاور دوم زاویه ای در سنگ های نوع A است و اگر با یک فیلتر مناسب
نویزهای تصاویر این دسته را از بین برده و ویژگی گشتاور دوم زاویه ای را در
آن متمرکز کنیم، دقت مدل به %100 خواهد رسید.

مراجع

1.  The Handbook of Pattern Recognition and Computer Vision (2nd
    Edition), by C. H. Chen, L. F. Pau,P. S. P. Wang (eds.), pp.
    207-248, World Scientific Publishing Co., 1998.

2.  ROBERT M, "Textural Features for Image Classification", IEEE
    TRNSACTIONS ON SYSTEMS, MAN AND CYBERNETICS, VOL. SMC-3,NOVEMBER
    1973

3.  Suresh**, "**Pattern Based Classification of Stone Textures on a
    Cubical Mask**",** International Journal of Universal Computer
    Sciences**,** 2010

4.  PANG- NING- TAN, "INTRODUCTION TO DATA MINING", Pearson Education,
    2006

![IUST-En](media/image28.jpeg){width="1.5493055555555555in"
height="1.6666666666666667in"}

Iran University of Science and Technology

Computer Engineering Department

Decorative Stone Type Recognition Based on Texture Classification

By:

Rasoul Masoudi

Supervisor:

Dr. Adel Torkman Rahmani

September 2012

[^1]: Segmentation

[^2]: Classification

[^3]: Recognition

[^4]: Visual Texture

[^5]: Coggins

[^6]: Texture Segmentation

[^7]: Texture Synthesis

[^8]: Julesz

[^9]: Textones

[^10]: Termination

[^11]: Closure

[^12]: Campbell

[^13]: Robson

[^14]: Valois

[^15]: Dewaele

[^16]: Chetverikov

[^17]: Chen

[^18]: Jain

[^19]: Conners

[^20]: Gray tone

[^21]: Tonal Features

[^22]: Siew

[^23]: Gabor

[^24]: Morphological

[^25]: Harm

[^26]: Landeweerd

[^27]: Gelsema

[^28]: Insana

[^29]: Chen

[^30]: Lundervold

[^31]: Brownian

[^32]: Wang

[^33]: Srihari

[^34]: Wahl

[^35]: Fletcher

[^36]: Kasturi

[^37]: Taxt

[^38]: Haralick

[^39]: Rignot

[^40]: Kwok

[^41]: Schistad

[^42]: Jain

[^43]: Markov Random Field

[^44]: Uniformity

[^45]: Density

[^46]: Coarseness

[^47]: Roughness

[^48]: Regularity

[^49]: Linearity

[^50]: Directionality

[^51]: Frequency

[^52]: Phase

[^53]: Picard

[^54]: Cardinality

[^55]: Segmentation

[^56]: Voxel

[^57]: Autocorrelation Features

[^58]: Teceryan

[^59]: Jain

[^60]: Token

[^61]: Ahuja

[^62]: Segmentation

[^63]: Voorhees

[^64]: Poggio

[^65]: Blostein

[^66]: Tomita

[^67]: Tsuji

[^68]: Zucker

[^69]: Fu

[^70]: Markov Random Fields

[^71]: Positivity

[^72]: Markovianity

[^73]: Homogenity

[^74]: Derrin- Elliot

[^75]: Autobinomial

[^76]: Cross

[^77]: Self Similarity

[^78]: Mandelbort

[^79]: Pentland

[^80]: Voss

[^81]: Supper

[^82]: Bovik

[^83]: Lacunarity

[^84]: Ohanian

[^85]: Dubes

[^86]: Spatial Domain Filters

[^87]: Malik

[^88]: Perona

[^89]: Descriptive Model

[^90]: Predictive Model

[^91]: Accuracy

[^92]: Hunt

[^93]: Maximal Margin Hyperplane

[^94]: Missclassification

[^95]: Structural Risk Minimization

[^96]: Angular Second Moment

[^97]: Variance

[^98]: Inverse Difference Moment

[^99]: Correlation
